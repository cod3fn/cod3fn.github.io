<search>
    
     <entry>
        <title>Posts</title>
        <url>https://xiongdahu.github.io/post/</url>
        <categories>
          
        </categories>
        <tags>
          
        </tags>
        <content type="html"> </content>
    </entry>
    
     <entry>
        <title>Scala Collection Tips</title>
        <url>https://xiongdahu.github.io/post/scala-collection-tips/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>scala</tag>
        </tags>
        <content type="html">  scala collection is high-performance,但是需要清楚一些常用的方法:
reduce fold scan
 集合的符号方法
 数组,tuple
 2.13的集合架构
  reduce fold scan //reduce是一个二元函数,遍历整个集合 List(1, 3, 5).reduceLeft(_ &#43; _) // == ((1&#43;3)&#43;5) //reduceRight start from end of the collection //also you can given initial argument List(1, 3, 5).foldLeft(&amp;#34;&amp;#34;)(_ &#43; _) // == 135 //foldLeft 等价于 \: 操作符 (0 /: List(1, 3, 5)) (_ - _) //folding 常用于替代for-loop val wf1 = scala.collection.mutable.Map[Char, Int]() for (c &amp;lt;- &amp;#34;Mississippi&amp;#34;) wf1(c) = wf1.getOrElse(c, 0) &#43; 1 // Now freq is Map(&amp;#39;i&amp;#39; -&amp;gt; 4, &amp;#39;M&amp;#39; -&amp;gt; 1, &amp;#39;s&amp;#39; -&amp;gt; 4, &amp;#39;p&amp;#39; -&amp;gt; 2)  //注意使用了不可变map val wf = (Map[Char, Int]() /: &amp;#34;Mississippi&amp;#34;) { (m, c) =&amp;gt; m &#43; (c -&amp;gt; (m.getOrElse(c, 0) &#43; 1)) } //scan 方法可以获得每一步中间结果集 (1 to 10).scanLeft(0)(_ &#43; _) //Vector(0, 1, 3, 6, 10, 15, 21, 28, 36, 45, 55) 集合的符号方法 //&#43; 表示添加一个元素到无序集合 // :&#43; &#43;:表示添加到有序集合的首/尾 //elem append or prepend to coll (Seq) coll :&#43; elem elem &#43;: coll //add elem to set/map coll &#43; elem coll &#43; (e1,e2,...) coll &#43;&#43; coll2 coll2 &#43;&#43;: coll // prepend to lst elem :: lst lst2 ::: lst // 等价list &#43;&#43;: list2 list ::: list2 // 含有=的表示修改,必须是mutable的集合  // TIP: As you can see, Scala provides many operators for adding and removing // elements. Here is a summary: // 1. Append (:&#43;) or prepend (&#43;:) to a sequence. // 2. Add (&#43;) to an unordered collection. // 3. Remove with the - operator. // 4. Use &#43;&#43; and -- for bulk add and remove. // 5. Mutations are &#43;= &#43;&#43;= -= --=. // 6. For lists, many Scala programmers prefer the :: and ::: operators. // 7. Stay away from &#43;&#43;: &#43;=: &#43;&#43;=:. NOTE: For lists, you can use &#43;: instead of :: for consistency, with one
exception: Pattern matching (case h::t) does not work with the &#43;: operator.
其他 //数组的笔记 val ints = new Array[Int](30) // empty array val ints2 = Array[Int](1, 2, 3, 4) // array with init values val matrix4x9 = Array.ofDim[Double](4, 9) //update ints2(3) = 1000 // or ints2.update(3, 1000) //求和 val ints2Sum = ints2.sum val days = Array(&amp;#34;Monday&amp;#34;, &amp;#34;Tuesday&amp;#34;, &amp;#34;Wednesday&amp;#34;, &amp;#34;Thrusday&amp;#34;, &amp;#34;Friday&amp;#34;, &amp;#34;Saturday&amp;#34;, &amp;#34;Sunday&amp;#34;) //遍历 for (i &amp;lt;- 0 until days.length) println(days(i)) for (day &amp;lt;- days) println(day) days foreach println //遍历中使用index days.zipWithIndex.map { case (e, i) =&amp;gt; (i, e) } //faster for (i &amp;lt;- days.indices) yield (i, days(i)) //Possibly fastest Array.tabulate(days.length) { i =&amp;gt; (i, days(i)) } //肯定最快 val b = new Array[(Int, String)](days.length) var i = 0 while (i &amp;lt; days.length) { b(i) = (i, days(i)) i &#43;= 1 } //filter days.filter(day =&amp;gt; day.length &amp;gt; 4) //map Array(1, 2, 3, 4, 5).map(x =&amp;gt; x * x) //sort Array(3, 6, 2, 0, 8, 5).sortWith((e1, e2) =&amp;gt; e1 &amp;lt; e2) //小的在前 //reduce,下面的会提示使用sum, Array(1, 2, 3, 4, 5).reduce((e1, e2) =&amp;gt; e1 &#43; e2) //不定长数组 import scala.collection.mutable.ArrayBuffer val arr = ArrayBuffer[Int]() //tuple val oneAndTwo = (1, 2) val oneAndTwo1 = Tuple2(1, 2) //Pair is alias of Tuple2 val oneAndTwo2 = Pair(1, &amp;#34;two&amp;#34;) val oneAndTwo3 = 1 -&amp;gt; 2 //访问元素下标是从1开始,这是因为tuple里面每个元素类型不一样,为了能够和list等区分开 //使用了类似Haskell/ML的习惯 val two = oneAndTwo._2 //option val emptyOpt: Option[Int] = None val fullOpt: Option[Int] = Some(42) emptyOpt match { case Some(value) =&amp;gt; println(value) case None =&amp;gt; println(&amp;#34;Empty&amp;#34;) } fullOpt.get //42 emptyOpt.isEmpty //true  //either def divide(a: Double, b: Double): Either[String, Double] = { if (b == 0.0) Left(&amp;#34;Division by zero&amp;#34;) else Right(a / b) } divide(4, 0) def either(flag: Boolean): Either[String, List[Int]] = { if (flag) Right(List(1, 2, 3)) else Left(&amp;#34;Wrong&amp;#34;) } val content = either(true).right.map(_.filter(_ &amp;gt; 0)) //cast Seq(1).toArray Seq(1).toBuffer Seq(1).toList Seq((1, 2)).toMap Seq(1).toStream Seq(1).toString Seq(1).toVector Seq(1).toTraversable Seq(1).toIndexedSeq Seq(1).toIterable Set(1).toSeq Seq(1).toSet //zip, zipAll, zipWithIndex, unzip &amp;#34;abcde&amp;#34; zip 1.to(5) //zipAll:第二个参数是调用者元素缺失使用的默认值,第三个参数是第一个实参不够长的默认值 &amp;#34;abcde&amp;#34;.zipAll(1.to(2), &amp;#34;caller&amp;#34;, &amp;#34;arg&amp;#34;) //尝试自己实现一个zipAll? // &amp;#34;abcde&amp;#34; zipWithIndex Seq((1, 2), (3, 4), (5, 6)) unzip // val s = Seq(&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;) scala 2.13 collection 基本重写了.参考这两个文档:
collections migration 2.13
the architecture of scala 2.13’s collections
</content>
    </entry>
    
     <entry>
        <title>前端静态资源图片优化</title>
        <url>https://xiongdahu.github.io/post/%E5%89%8D%E7%AB%AF%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E5%9B%BE%E7%89%87%E4%BC%98%E5%8C%96/</url>
        <categories>
          <category>翻译</category>
        </categories>
        <tags>
          <tag>code</tag>
        </tags>
        <content type="html"> GTmetrix是一个前端页面测试的网站,可以发现你的站点哪些地方速度较慢,并针对性的优化.
How to Optimize Images: A Practical Guide
</content>
    </entry>
    
     <entry>
        <title>Spring FactoryBean and ContextAware</title>
        <url>https://xiongdahu.github.io/post/spring-factorybean-contextaware/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>spring</tag>
        </tags>
        <content type="html">  FactoryBean 一句话就是FactoryBean用于返回其他对象实例的,而不是自身类型的实例.
例如:
public class Tool { private int id; // standard constructors, getters and setters } public class ToolFactory implements FactoryBean&amp;lt;Tool&amp;gt; { private int factoryId; private int toolId; @Override public Tool getObject() throws Exception { return new Tool(toolId); } @Override public Class&amp;lt;?&amp;gt; getObjectType() { return Tool.class; } @Override public boolean isSingleton() { return false; } // standard setters and getters } 注册Tool:
&amp;lt;!-- factorybean-spring-ctx.xml --&amp;gt; &amp;lt;beans ...&amp;gt; &amp;lt;bean id=&amp;#34;tool&amp;#34; class=&amp;#34;com.baeldung.factorybean.ToolFactory&amp;#34;&amp;gt; &amp;lt;property name=&amp;#34;factoryId&amp;#34; value=&amp;#34;9090&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;toolId&amp;#34; value=&amp;#34;1&amp;#34;/&amp;gt; &amp;lt;/bean&amp;gt; &amp;lt;/beans&amp;gt; 使用注解注册:
@Bean(name = &amp;#34;tool&amp;#34;) public ToolFactory toolFactory() { ToolFactory factory = new ToolFactory(); factory.setFactoryId(7070); factory.setToolId(2); return factory; } 使用Tool:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { &amp;#34;classpath:factorybean-spring-ctx.xml&amp;#34; }) public class FactoryBeanXmlConfigTest { @Autowired private Tool tool; @Test public void testConstructWorkerByXml() { assertThat(tool.getId(), equalTo(1)); } } 访问ToolFactory,在bean id前面添加 &amp;amp;:
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = { &amp;#34;classpath:factorybean-spring-ctx.xml&amp;#34; }) public class FactoryBeanXmlConfigTest { @Resource(name = &amp;#34;&amp;amp;tool&amp;#34;) private ToolFactory toolFactory; @Test public void testConstructWorkerByXml() { assertThat(toolFactory.getFactoryId(), equalTo(9090)); } } 和BeanFactory的区别 除了FactoryBean,还有一个BeanFactory的接口及其实现.
</content>
    </entry>
    
     <entry>
        <title>Learn Clojure by Example</title>
        <url>https://xiongdahu.github.io/post/learn-clojure-by-example/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>clojure</tag>
        </tags>
        <content type="html">  这份笔记试图打造最强的clojure小抄,keep refactoring it&amp;hellip; (ns learnclj.core (:gen-class)) ;准备:在leiningen网站下载lein.bat,放到一个目录下 ;将目录添加到windows的path中 ;打开cmder,执行 lein self-install ;leiningen安装完成后继续执行: lein repl (println &amp;#34;the joy of clojure&amp;#34;) ;如果你使用scoop,那么执行`scoop install leiningen`后即可使用: lein repl (def -main (println &amp;#34;hello clojure&amp;#34;)) ;Parameter is variable in the declaration of function. ;Argument is the actual value of this variable that gets passed to function. ; ;Symbols are used to bind names to values ;&amp;#39; will prevent a form from being evaluated ;&amp;#39;() same as (quote ()) ;def 定义全局变量 ;let 局部变量 (def color &amp;#34;light&amp;#34;) (println color) (let [x 10 y 20 z 30]) ;=========data collection ;list is the core of clojure &amp;#39;(1, 2, &amp;#34;jam&amp;#34; :marmalade-jar) ;逗号在clojure中会被忽略,所以使用空格就好 ;vector has index,you have fast index access to the elements (nth [:jar1 1 2 3 :jar2] 1) ;return the 0th element-&amp;gt;1 ; conj adds to a collection in the most natural way for the data structure. ; For lists, it adds to the beginning. ; For vectors, it adds to the end. (conj &amp;#39;(:toast :butter) :jam :honey) ;=&amp;gt; (:honey :jam :toast :butter) ;map (def dict {:k1 &amp;#34;v1&amp;#34; :k2 &amp;#34;v2&amp;#34;}) ;keyword as function (:k1 dict) ;=&amp;gt; v1 ;map as function (dict :k1) ;=&amp;gt; v1 ;also you can use get on seq or map (get {:a 1 :b 2} :b) ;also you have keys,vals function on map ;and assoc (assoc {:Apple &amp;#34;Mac&amp;#34; :Microsoft &amp;#34;Windows&amp;#34;} :Commodore &amp;#34;Amiga&amp;#34;) ;=&amp;gt; {:jam2 &amp;#34;black&amp;#34;, :jam1 &amp;#34;orange&amp;#34;} (dissoc {:jam1 &amp;#34;strawberry&amp;#34; :jam2 &amp;#34;blackberry&amp;#34;} :jam1) ;=&amp;gt; {:jam2 &amp;#34;blackberry&amp;#34;} (merge {:jam1 &amp;#34;red&amp;#34; :jam2 &amp;#34;black&amp;#34;} {:jam1 &amp;#34;orange&amp;#34; :jam3 &amp;#34;red&amp;#34;} {:jam4 &amp;#34;blue&amp;#34;}) ;=&amp;gt; {:jam4 &amp;#34;blue&amp;#34;, :jam3 &amp;#34;red&amp;#34;, :jam2 &amp;#34;black&amp;#34;, :jam1 &amp;#34;orange&amp;#34;} ;set (let [s #{:red :blue :white :pink}] (println (get s :red))) ;:red (clojure.set/union #{:r :b :w} #{:w :p :y}) ;=&amp;gt; #{:y :r :w :b :p} (get #{:rabbit :door :watch} :jar) ;; =&amp;gt; nil ;remove element from set (disj #{:rabbit :door} :door) ;=&amp;gt; #{:rabbit} ;clojure.core/seq is a function that produces a sequence over the given argument. ;Data types that clojure.core/seq can produce a sequence over are called seqable: ; ;Clojure collections ;Java maps ;All iterable types (types that implement java.util.Iterable) ;Java collections (java.util.Set, java.util.List, etc) ;Java arrays ;All types that implement java.lang.CharSequence interface, including Java strings ;All types that implement clojure.lang.Seqable interface ;nil ; Test to see if a collection is empty with emtpy? ; Test to see if a collection is not empty with seq ; Test to see if all the elements test true with every? ; Test to see if all of the elements test false with not-any? ; Test to see if some of the elements test true with some ; true? tests for true values ; false? tests for false values ; nil is treated the same as logical false ; nil is treated the same as logical false (repeated on purpose — false and nil are the ; only logically false values) ; nil? tests for the absence of a value ; not tests for the negation of the value ; = tests for equality ; not= tests for inequality ;repeatedly (repeatedly 5 (fn [] (println &amp;#34;hi!&amp;#34;))) ;for each (doseq [animal [&amp;#34;cat&amp;#34; &amp;#34;dog&amp;#34; &amp;#34;horse&amp;#34;]] (println animal)) ;laziness (take 5 (range 0 100)) ;危险!死循环 (range) (take-while neg? [-3 -2 -1 0 1 2 3]) ;drop will remove the first n elements (drop 5 (range 0 10)) (drop-while neg? [-3 -2 -1 0 1 2 3]) ;=&amp;gt; (0 1 2 3) (remove pos? [-1 -2 3 4]) ;=&amp;gt; (-1 -2) (filter pos? [-1 2 3]) (partition-by #(&amp;lt; 3 %) [1 2 3 4 5 6]) ;=&amp;gt; ((1 2 3) (4 5 6)) (group-by #(&amp;lt; 3 %) [1 2 3 4 5 6 1 2 3]) ;{false [1 2 3 1 2 3], true [4 5 6]} (println (take 5 (iterate inc 0))) ;for (for [x &amp;#39;(1 2 3)] (&#43; 10 x)) (doc for) ;双重for 循环 (for [x (range 10) y (range 20) :while (&amp;lt; y x)] [x y]) ;&amp;lt;==&amp;gt; {x | x &amp;gt;0} (for [x &amp;#39;(-1 1 2) :when (&amp;gt; x 0)] x) (for [x [0 1 2 3 4 5] :let [y (* x 3)] :when (even? y)] y) ;=========function ;defn 定义函数 ;defn- 定义ns内私有函数 ;fn 定义匿名函数 ;函数格式: ;(defn name doc-string? attr-map? [params*] prepost-map? body) ;(defn name doc-string? attr-map? ([params*] prepost-map? body) &#43; attr-map?) (defn f &amp;#34;the second line is doc-string&amp;#34; {:added &amp;#34;1.2&amp;#34; ;this is attr-map :static true} [param] (print &amp;#34;hello &amp;#34; param)) (meta (var f)) ;#&amp;#39; is the reader macro for var and works the exactly same (meta #&amp;#39;f) ;=&amp;gt; ; {:added &amp;#34;1.2&amp;#34;, ; :ns #object[clojure.lang.Namespace 0x79876e95 &amp;#34;learnclj.core&amp;#34;], ; :name f, ; :file &amp;#34;/code/clj/clj-notes/src/learnclj/core.clj&amp;#34;, ; :static true, ; :column 1, ; :line 157, ; :arglists ([param]), ; :doc &amp;#34;the second line is doc-string&amp;#34;} ;function can have params type hint (defn round &amp;#34;^double here is type hint&amp;#34; [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;重载函数,即参数可不同 (defn bar ([a b] (bar a b 100)) ([a b c] (* a b c))) (bar 5 6) (bar 5 6 3) ;fn create a function object (def f (fn [] (println &amp;#34;this is from fn function&amp;#34;))) ;#() is the shortcut for fn (def plus-one #(&#43; 1 %)) ;% will be replaced with arguments passed to the function ;%1 is for the first argument, %2 is for the second and so on ;=========boolean and flow control ;In Clojure, everything except false and nil are true. (if 1 (println &amp;#34;it is true&amp;#34;) (println &amp;#34;will never print&amp;#34;)) ;if (if true (println &amp;#34;executed when true&amp;#34;) (println &amp;#34;executed when false&amp;#34;)) ;use do to execute multi expressions (if true (do (println &amp;#34;one&amp;#34;) (println &amp;#34;two&amp;#34;))) ;if-let: (defn positive-number [numbers] (if-let [pos-nums (not-empty (filter pos? numbers))] pos-nums &amp;#34;no positive numbers&amp;#34;)) ;when when-let case cond condp ; (defn cond-test [n] (cond (= n 1) &amp;#34;n is 1&amp;#34; (and (&amp;gt; n 3) (&amp;lt; n 10)) &amp;#34;n is over 3 and under 10&amp;#34; :else &amp;#34;n is other&amp;#34;)) (cond-test 1000) ;string (let [first &amp;#34;Hirokuni&amp;#34; last &amp;#34;Kim&amp;#34;] (str &amp;#34;My name is &amp;#34; first &amp;#34; &amp;#34; last)) ;format (format &amp;#34;My name is %s %s&amp;#34; &amp;#34;Hirokuni&amp;#34; &amp;#34;Kim&amp;#34;) ;power function (defn power [x n] (reduce * (repeat n x))) ;bigint,N is a literal for bigint ;decimal literal is use M postfix (&#43; 9223372036854775807 10N) ;=&amp;gt; 9223372036854775817N ;=========destructing map arguments !!!大杀器 ;get value of :k1 from argument (map) and binding it to p1(parameter) (defn des [{p1 :k1}] (println &amp;#34;the :k1 in argument is: &amp;#34; p1)) (des {:k1 &amp;#34;clojure&amp;#34; :k2 &amp;#34;java&amp;#34;}) ;=&amp;gt; the :k1 in argument is: clojure ;定义一个计算总价的函数 总价=单价*数量 ;key don&amp;#39;t have to be keyword,symbol and string is also allowed (defn total-price [{unit &amp;#34;unit&amp;#34;}] unit) (defn total-price [{unit &amp;#39;unit}] unit) ;if want to destructing multi key,use :keys, ;in this case,parameter name(currency amount) ;must same as arguments&amp;#39;s keys(:currency :amount),can not use string as key (defn total-price [{:keys [unit amount]}] (* unit amount)) (total-price {:unit 2.0 :amount 10}) ;ok (total-price {&amp;#34;unit&amp;#34; 2.0 &amp;#34;amount&amp;#34; 5}) ;unit will be nil,you will need use :strs or syms (defn total-price-strs [{:strs [unit amount]}] (* unit amount)) (total-price-strs {&amp;#34;unit&amp;#34; 2.0 &amp;#34;amount&amp;#34; 5}) ;ok (defn total-price-syms [{:syms [unit amount]}] (* unit amount)) (total-price-syms {&amp;#39;unit 2.0 &amp;#39;amount 5}) ;ok ;use :or to give a default value for parameter ;单价默认5元 (defn total-price-or [{:keys [unit amount] :or {unit 5.0}}] (* unit amount)) (total-price-or {:amount 5}) ;=&amp;gt; 25.0 ;不定长参数 ;use &amp;amp; for Variadic Functions Parameters ;&amp;amp; 表示the rest的意思 ;!!! There is no &amp;amp; rest for maps. (defn log [message &amp;amp; args] (println &amp;#34;args: &amp;#34; args)) (log &amp;#34;this is msg&amp;#34; 2 3) ;args: (2 3) ;named params , achieved by Variadic Functions destructing ;everything but false and nil evaluates to true in Clojure. (defn job-info [&amp;amp; {:keys [name job income] :or {job &amp;#34;unemployed&amp;#34; income &amp;#34;$0.00&amp;#34;}}] (if name [name job income] (println &amp;#34;No name specified&amp;#34;))) ;cation! arguments to job-info is not a map (job-info :name &amp;#34;Robert&amp;#34; :job &amp;#34;Engineer&amp;#34;) ;[&amp;#34;Robert&amp;#34; &amp;#34;Engineer&amp;#34; &amp;#34;$0.00&amp;#34;] ;Without the use of a variadic argument list, ;you would have to call the function with a single map argument such as (job-info {:name &amp;#34;Robert&amp;#34; :job &amp;#34;Engineer&amp;#34;}) ; :as bind entire map to param ;See https://github.com/ring-clojure/ring/wiki/File-Uploads for explanation (defn show-request ; 将整个http请求参数(header body method query-string)绑定到request [{:as request}] (println request)) (defn file-handler ;先绑定request,然后入参map还有一个key为:params,:params也是一个map,里面有个key是&amp;#34;file&amp;#34;(其实就是上传文件表单名), ;&amp;#34;file&amp;#34; 里面2个参数分别是文件对象和上传文件名 [{:as request {{file :tempfile fname :filename} &amp;#34;file&amp;#34;} :params}] (println request) (let [n (num-lines file)] (response (str &amp;#34;File &amp;#34; fname &amp;#34; has &amp;#34; n &amp;#34; lines &amp;#34;)))) ;总结一下: map的解构,无论是单层还是嵌套map,:keys,:as,:syms这些函数一定是在左边的,右边是形参,例如上面的request ;而如要获取具体的某个实参,则实参名在右边(:params,&amp;#34;file&amp;#34;,:filename,:tempfile),形参在左边(file,fname) ;:as request 可以放在最前面,也可以放在最后 ;这里理解的不够,应该是宏有关的知识点 ;vector也可以解构 ;more destructuring example ;https://gist.github.com/john2x/e1dca953548bfdfb9844 (def my-vec [1 2 3]) (let [[a b c d] my-vec] (println a b c d)) ;1 2 3 nil (let [[a b &amp;amp; the-rest] my-vec] (println &amp;#34;a=&amp;#34; a &amp;#34;b=&amp;#34; b &amp;#34;the-rest=&amp;#34; the-rest)) ;a= 1 b= 2 the-rest= (3) (let [[:as all] my-vec] (println all)) ;[1 2 3] (let [[a :as all] my-vec] (println a all)) ;1 [1 2 3] (let [[a b &amp;amp; the-rest :as all] my-vec] (println a b the-rest all)) ;1 2 (3) [1 2 3] ;note: &amp;amp; the-rest convert vector to list, ;but :as preserves them (as a list, or as a vector) (def my-vec [&amp;#34;first&amp;#34; &amp;#34;second&amp;#34;]) (let [{a 0 b 1} my-vec] (println a b)) ;=&amp;gt; &amp;#34;first second&amp;#34; ;optional arguments to functions (defn foo [a b &amp;amp; more-args] (println a b more-args)) (foo :a :b) ;; =&amp;gt; :a :b nil (foo :a :b :x) ;; =&amp;gt; :a :b (:x) (foo :a :b :x :y :z) ;; =&amp;gt; :a :b (:x :y :z) ;map destructuring (def my-hashmap {:a &amp;#34;A&amp;#34; :b &amp;#34;B&amp;#34; :c &amp;#34;C&amp;#34; :d &amp;#34;D&amp;#34;}) (def my-nested-hashmap {:a &amp;#34;A&amp;#34; :b &amp;#34;B&amp;#34; :c &amp;#34;C&amp;#34; :d &amp;#34;D&amp;#34; :q {:x &amp;#34;X&amp;#34; :y &amp;#34;Y&amp;#34; :z &amp;#34;Z&amp;#34;}}) (let [{a :a d :d} my-hashmap] (println a d)) ;; =&amp;gt; A D (let [{a :a, b :b, {x :x, y :y} :q} my-nested-hashmap] (println a b x y)) ;; =&amp;gt; A B X Y (let [{a :a, b :b, not-found :not-found, :or {not-found &amp;#34;:)&amp;#34;}, :as all} my-hashmap] (println a b not-found all)) ;; =&amp;gt; A B :) {:a A :b B :c C :d D} ; 嵌套数组的解构 (defn first-first ;数组的第二维的第一个元素 [[[i _] _]] i) (first-first [[[5 2] [3 4] [6]]]) ;=&amp;gt; [5 2] ; 使用&amp;amp;实现命名参数,这里的&amp;amp;不是rest,调用的时候传入的实参也不是map (defn named-args-fun [&amp;amp; {:keys [function sequence]}] (map function sequence)) ; 调用,实参顺序可以和函数声明的不同 (named-args-fun :sequence [1 2 3] :function #(&#43; % 2)) ;=&amp;gt; (3 4 5) ;=========namespace ;create-ns create a namespace (create-ns &amp;#39;com.xiongdahu.clj) ;in-ns move to a namespace ;require loads a namespace and ;refer refers the namespace. ;To do these(require and refer) at once, you can use use (require &amp;#39;clojure.by.example) (clojure.by.example/favorite-language) (use &amp;#39;clojure.by.example) ;you can rename namespace (require &amp;#39;[clojure.by.example :as example]) ;ns macro creates a new namespace and gives you an opportunity to load other namespaces at the creation time ;import java class (import java.util.Date) ;========= repl utils functions (doc iterate) ;meta data for function parameters (defn round &amp;#34;^double 用于IDE的代码提示,可以说非常有用了,但是代码可读性变差了,如果可以有个注解的形式就好了,不要夹杂在函数体里面&amp;#34; [^double d ^long precision] (let [factor (Math/pow 10 precision)] (/ (Math/floor (* d factor)) factor))) ;# is Dispatch character that tells the Clojure reader how to interpret the next character using a read table ;set #{1 2 3} ;discard {:a 1, #_#_:b 2, :c 3} ;regular expression (re-matches #&amp;#34;^test$&amp;#34; &amp;#34;test&amp;#34;) ;var quote (read-string &amp;#34;#&amp;#39;foo&amp;#34;) ;symbolic values (/ 1.0 0.0) ;##Inf ;tagged literals (type #inst &amp;#34;2014-05-19T19:12:37.925-00:00&amp;#34;) ;java.util.Date ;meta (meta #&amp;#39;fn-name) ;reader conditionals #?(:clj (Clojure expression) :cljs (ClojureScript expression) :cljr (Clojure CLR expression) :default (fallthrough expression)) ;#?@ splicing reader conditional (defn build-list [] (list #?@(:clj [5 6 7 8] :cljs [1 2 3 4]))) ;return [5 6 7 8] when run on clojure ;#= allows the reader to evaluate an arbitrary form during read time (read-string &amp;#34;#=(&#43; 3 4)&amp;#34;) ;7 ;=========Recursion ;simple recursion (defn fibo &amp;#34;this is recursion function&amp;#34; [n] (if (or (= n 0) (= n 1)) n (&#43; (fibo (- n 1)) (fibo (- n 2))))) ;do not do this!!! take a long time to finish (fibo 1000) ;use recur (defn fibo-recur [iteration] (let [fibo (fn [one two n] (if (= iteration n) one (recur two (&#43; one two) (inc n))))] ;recur re-binds it&amp;#39;s arguments to new values and call the function with the new values ;fibo is an inner function (fibo 0N 1N 0))) (fibo-recur 1000) ;it is really fast ;notes ;with simple recursion, each recursive call creates a stack frame which is ;a data to store the information of the called function on memory. ;Doing deep recursion requires large memory for stack frames, but since it cannot, ;we get StackOverflowError ;尾递归: ;A function is tail recursive when the recursion is happening at the end of it&amp;#39;s definition ;In other words, a tail recursive function must return itself as it&amp;#39;s returned value. ;When you use recur, it makes sure you are doing tail recursion (doc loop) ;loop/recur is merely a friendly way to write recursion code. ;All imperative loops can be converted to recursions and all recursions can be converted to loops, ;so Clojure chose recursions. ;Although you can write code that looks like an imperative loop with loop/recur, ;Clojure is doing recursion under the hood. ;;DON&amp;#34;T EVALUATE THIS OR YOUR REPL WILL CRASH ;下面是死循环 (range) ;=========macro and thread(不是线程) (defmacro unless [test then] &amp;#34;Evaluates then when test evaluates to be falsey&amp;#34; (list &amp;#39;if (list &amp;#39;not test) then)) (macroexpand &amp;#39;(unless false (println &amp;#34;hi&amp;#34;))) ;&amp;#39; quoting ;` syntax-quoting returns the fully qualified namespace. ;Using fully qualified namespace is very important in order to avoid name conflicts when defining macro. ;~ unquote `(&#43; ~(list 1 2 3)) ;(clojure.core/&#43; (1 2 3)) `(&#43; ~@(list 1 2 3)) ;(clojure.core/&#43; 1 2 3) ;The ~@ unquote splice works just like ~ unquote, ;except it expands a sequence and splice the contents of ;the sequence into the enclosing syntax-quoted data structure ;thread first macro (-&amp;gt; [] (conj 1) (conj 2) (conj 3)) ;[1 2 3] (first (.split (.replace (.toUpperCase &amp;#34;a b c d&amp;#34;) &amp;#34;A&amp;#34; &amp;#34;X&amp;#34;) &amp;#34; &amp;#34;)) ;&amp;#34;X&amp;#34; ;;Perhaps easier to read: ;-&amp;gt; 后面是初始参数,第2行开始每一行是一个函数调用, ;且上一行的返回值会作为这一行第一个参数(这就是thread first)的first含义 ;这里的thread是管道的意思,而不是并发编程的线程 ;如果省略(),那么野生符号(bare symbol)和keyword都会当作一个函数调用, ;例如,这里的.toUpperCase是bare symbol,等效于(.toUpperCase ,,,) ;clojure中 逗号等于空白符,所以上面用,,,表示将会插入的参数(即&amp;#34;a b c d&amp;#34;) (-&amp;gt; &amp;#34;a b c d&amp;#34; .toUpperCase (.replace &amp;#34;A&amp;#34; &amp;#34;X&amp;#34;) (.split &amp;#34; &amp;#34;) first) ;same as follow, ,,, is equals whitespace (-&amp;gt; &amp;#34;a b c d&amp;#34; (.toUpperCase,,,) (.replace &amp;#34;A&amp;#34; &amp;#34;X&amp;#34;) (.split &amp;#34; &amp;#34;) first) ;suppose a function (defn calculate [] (reduce &#43; (map #(* % %) (filter odd? (range 10))))) ;same as ;上一行的结果作为最后一个参数插入,这叫thread last (defn calculate* [] (-&amp;gt;&amp;gt; (range 10) (filter odd?,,,) (map #(* % %),,,) (reduce &#43;,,,))) ;如果想要指定每次插入的位置那么需要用 as-&amp;gt; ;v是每一行的返回值的名称,这样你可以在下一行任意参数位置指定 (as-&amp;gt; [:foo :bar] v (map name v) (first v) (.substring v 1)) ;future and deref (let [future-val (future (inc 1))] (println (deref future-val))) ;deref == @ (let [future-val (future (inc 1))] (println @future-val)) (def my-future (future (Thread/sleep 5000))) (repeatedly 6 (fn [] (println (realized? my-future)) (Thread/sleep 1000))) (doc future) ;promise (def my-promise (promise)) ;you define a promise (def listen-and-callback (fn [] (println &amp;#34;Start listening...&amp;#34;) (future (println &amp;#34;Callback fired: &amp;#34; @my-promise)))) (defn do-time-consuming-job [] (Thread/sleep 5000) (deliver my-promise &amp;#34;delivered value&amp;#34;)) (listen-and-callback) (do-time-consuming-job) ;atom is like mutable var in other languages but atom is thread safe ;ref dosync ref-set alter (def my-ref (ref 0)) (dosync (alter my-ref (fn [current_ref] (inc current_ref)))) (print @my-ref) (def user (ref {})) (dosync (alter user merge {:name &amp;#34;Kim&amp;#34;}) (throw (Exception. &amp;#34;something wrong happens!&amp;#34;)) (alter user merge {:age 32})) (def user-record (atom {})) (do (swap! user-record merge {:name &amp;#34;Kim&amp;#34;}) (throw (Exception. &amp;#34;something wrong happens!&amp;#34;)) (swap! user-record merge {:age 32})) ;=========Java (new java.util.Date &amp;#34;2016/2/19&amp;#34;) (java.util.Date.) (java.util.Date. &amp;#34;2016/2/19&amp;#34;) (Math/pow 2 3) ;static method (def rnd (new java.util.Random)) (. rnd nextInt 10) (let [date1 (new java.util.Date) date2 (new java.util.Date)] (.equals date1 date2)) ;(.instanceMember instance args*) ;(.instanceMember Classname args*) ;(.-instanceField instance) ;(Classname/staticMethod args*) ;Classname/staticField ;========= ;;;a ring file upload example (ns learnclj.file-upload (:require [ring.middleware.params :refer :all] [ring.util.response :refer :all] [ring.middleware.multipart-params :refer :all] [ring.adapter.jetty :as jetty]) (:gen-class)) (defn- num-lines [file] (with-open [rdr (clojure.java.io/reader file)] (count (line-seq rdr)))) (defn file-handler [{{{tempfile :tempfile filename :filename} &amp;#34;file&amp;#34;} :params :as request}] (println request) (let [n (num-lines tempfile)] (response (str &amp;#34;File &amp;#34; filename &amp;#34; has &amp;#34; n &amp;#34; lines &amp;#34;)))) (defn -main &amp;#34;I start a server which counts lines of text in your .txt files :)&amp;#34; [&amp;amp; args] (jetty/run-jetty (-&amp;gt; file-handler wrap-params wrap-multipart-params) {:port 3000})) ;;;a ring file upload example end</content>
    </entry>
    
     <entry>
        <title>Elasticsearch Query DSL</title>
        <url>https://xiongdahu.github.io/post/elasticsearch-query-dsl/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>elasticsearch</tag>
        </tags>
        <content type="html">  diffs in es 2.x and es 5.x
 query dsl
 aggr query
  diffs in es 2.x and es 5.x 没有string类型，改为text和keyword 2个类型了。text字段可以指定fields来不分词。如下： city字段被ingest为city和city.raw2个字段。 { &amp;#34;mappings&amp;#34;: { &amp;#34;_doc&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;city&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;text&amp;#34;, &amp;#34;fields&amp;#34;: { &amp;#34;raw&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;keyword&amp;#34;, &amp;#34;ignore_above&amp;#34;: 256 } } } } } } }  default double -&amp;gt; float geo_point //2.x &amp;#34;location&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;geo_point&amp;#34;, &amp;#34;lat_lon&amp;#34;: true, &amp;#34;geohash&amp;#34;: true, &amp;#34;geohash_prefix&amp;#34;: true, &amp;#34;geohash_precision&amp;#34;: &amp;#34;1m&amp;#34; } //5.x &amp;#34;location&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;geo_point&amp;#34; }  query dsl basic query 就像砌房子的砖头，基本查询就是ES查询的砖头。基本查询是组合查询，bool查询的单元。基本查询有：
//basic query element match, multi_match, common, fuzzy_like_this, geoshape, ids, match_all, query_string, simple_query_string, range, prefix, regexp, span_term, term, terms, wildcard  其中common, ids, prefix, span_term, term, terms, wildcard 是不分析搜索，match, multi_match, query_string, simple_query_string是全文检索，几乎可以确保可以返回结果。而prefix,regexp,wildcard是模式检索。
组合查询 bool, boosting, constant_score, dis_max, filtered,function_score, has_child, has_parent, indices, nested, span_first, span_multi,span_first, span_multi, span_near, span_not, span_or, span_term, top_children  bool bool查询的外框架结构为：
{ &amp;#34;query&amp;#34;: { &amp;#34;bool&amp;#34;: { &amp;#34;must&amp;#34;: [ {} ], &amp;#34;should&amp;#34;: [ {} ], &amp;#34;must_not&amp;#34;: [ {} ], &amp;#34;filter&amp;#34;: [ {} ] } } } //some other parameter for bool: boost,minimum_should_match,disable_coord </content>
    </entry>
    
     <entry>
        <title>Useful Scala Code Snippets</title>
        <url>https://xiongdahu.github.io/post/useful-scala-code-snippets/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>scala</tag>
        </tags>
        <content type="html">  merge two map and sum its values 多个map合并,key相同时则value相加
val map1 = Map(1 -&amp;gt; 1, 2 -&amp;gt; 2) val map2 = Map(1 -&amp;gt; 11, 3 -&amp;gt; 3) val map3 = Map(1 -&amp;gt; 111, 3 -&amp;gt; 3) val mapList = List(map1, map2, map3) val merged = mapList.reduce((m1, m2) =&amp;gt; m1 &#43;&#43; m2.map { case (k, v) =&amp;gt; k -&amp;gt; (v &#43; m1.getOrElse(k, 0)) } ) 文件读 // &amp;#34;&amp;#34;&amp;#34;&amp;#34;&amp;#34;&amp;#34;可以避免\\符号 val file = &amp;#34;&amp;#34;&amp;#34;d:\data\file.txt&amp;#34;&amp;#34;&amp;#34; for (line &amp;lt;- Source.fromFile(file, encoding).getLines()) { print(line) } 文件写 //资源管理  def using[A &amp;lt;: {def close() : Unit}, R](resource: A)(fun: A =&amp;gt; R): R = { import scala.language.reflectiveCalls try { fun(resource) } finally { resource.close() } } using(new OutputStreamWriter(new FileOutputStream(outputFile), StandardCharsets.UTF_8)) { writer =&amp;gt; writer.write(s&amp;#34;&amp;#34;&amp;#34;${line}\n&amp;#34;&amp;#34;&amp;#34;) } 统计词频 val nanoUnit = 1000000 //分词并统计词频  def main(args: Array[String]): Unit = { val path = &amp;#34;&amp;#34;&amp;#34;D:\code\ideaProjects\scala-notes\data\src\out&amp;#34;&amp;#34;&amp;#34; val files: List[File] = new File(path).listFiles.filter(_.isFile).toList val start = System.nanoTime() val wfList = ListBuffer[mutable.Map[String, Long]]() val futures = for (file &amp;lt;- files) yield Future { countWrodsInFile(file, &amp;#34;UTF-8&amp;#34;) } for (f &amp;lt;- futures) { val words: mutable.Map[String, Long] = Await.result(f, Duration.Inf) wfList &#43;= words } //merge the word frequency map  val finalWf = wfList.reduce((m1, m2) =&amp;gt; m1 &#43;&#43; m2.map { case (k, v) =&amp;gt; k -&amp;gt; (v &#43; m1.getOrElse(k, 0L)) } ) val end = System.nanoTime() println(s&amp;#34;container size=${finalWf.size}&amp;#34;) // sort map  val wordsFreq = finalWf.toList.sortWith(_._2 &amp;gt; _._2) write2file(wordsFreq, Paths.get(path, &amp;#34;final.txt&amp;#34;).toFile) println(s&amp;#34;total used time = ${(end - start) / nanoUnit}ms&amp;#34;) println(s&amp;#34;cups = ${Runtime.getRuntime.availableProcessors()}&amp;#34;) } def countWrodsInFile(file: File, encoding: String): mutable.Map[String, Long] = { val wf = mutable.Map[String, Long]().withDefaultValue(0) for (line &amp;lt;- Source.fromFile(file, encoding).getLines()) { val l = line.trim wf.update(l, wf(l) &#43; 1) } println(s&amp;#34;${file.getName}has words:${wf.size}&amp;#34;) wf } def write2file(wf: Seq[(String, Long)], out: File): Unit = { using(new OutputStreamWriter(new FileOutputStream(out), StandardCharsets.UTF_8)) { writer =&amp;gt; for (it &amp;lt;- wf) { writer.write(s&amp;#34;&amp;#34;&amp;#34;${it._1}${it._2}\n&amp;#34;&amp;#34;&amp;#34;) } } }</content>
    </entry>
    
     <entry>
        <title>Scala Future</title>
        <url>https://xiongdahu.github.io/post/scala-future/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>scala</tag>
        </tags>
        <content type="html"> some notes on scala future, includes:
future
 executor context
 await future result
 callback
 recover
  future import java.time._ import scala.concurrent._ import ExecutionContext.Implicits.global Future { Thread.sleep(10000) println(s&amp;#34;This is the future at ${LocalTime.now}&amp;#34;) } println(s&amp;#34;This is the present at ${LocalTime.now}&amp;#34;) executor context future need a new thread to execute it task. import ExecutionContext.Implicits.global is a implicit threadpool.
await for future result // for 10.seconds conversion import scala.concurrent.duration._ val f = Future { Thread.sleep(10000); 42 } val result = Await.result(f, Duration.Inf) // if f throw exception, it will rethrow to Await.result // use ready() solve this val f = Future { ... } Await.ready(f, 10.seconds) val Some(t) = f.value // The f.value method returns an Option[Try[T]], // which is None when the future is not completed // and Some(t) when it is is  // t is Try type instance // A Try[T] instance is either a Success(v), where v is a value of type T or a Failure(ex) val t = Some(t).get t match { case Success(v) =&amp;gt; println(s&amp;#34;The answer is $v&amp;#34;) case Failure(ex) =&amp;gt; println(ex.getMessage) } // or if (t.isSuccess) println(s&amp;#34;The answer is ${t.get}&amp;#34;) callback val f = Future { Thread.sleep(10000) if (random() &amp;lt; 0.5) throw new Exception 42 } f.onComplete { case Success(v) =&amp;gt; println(s&amp;#34;The answer is $v&amp;#34;) case Failure(ex) =&amp;gt; println(ex.getMessage) } callback hell val future1 = Future { getData1() } val future2 = Future { getData2() } future1 onComplete { case Success(n1) =&amp;gt; future2 onComplete { case Success(n2) =&amp;gt; { val n = n1 &#43; n2 println(s&amp;#34;Result: $n&amp;#34;) } case Failure(ex) =&amp;gt; ... } case Failure(ex) =&amp;gt; ... } // improve val future1 = Future { getData1() } val combined = future1.map(n1 =&amp;gt; n1 &#43; getData2()) // val future1 = Future { getData1() } val future2 = Future { getData2() } val combined = future1.map(n1 =&amp;gt; future2.map(n2 =&amp;gt; n1 &#43; n2)) // use for-yield  for ( n1 &amp;lt;- future1 n2 &amp;lt;- future2 ) yield n1&#43;n2</content>
    </entry>
    
     <entry>
        <title>Spring Boot Notes</title>
        <url>https://xiongdahu.github.io/post/spring-boot-notes/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>spring</tag>
        </tags>
        <content type="html">  一些容易忘记的spring boot知识要点.
 注意,.yaml和.yml文件没用任何区别.
 配置 SpringBootApplication注解 @SpringBootApplication &amp;lt;=等价=&amp;gt; @Configuration @ComponentScan @EnableAutoConfiguration 自动配置 spring的自动配置依赖以下注解:
配置文件 任何时候硬编码的配置总是不好的,spring支持从很多环境中读取配置: 配置文件,yaml文件,环境变量,命令参数.
配置可以在@Value注解中使用,也可Environment访问,或者通过@ConfigurationProperties将配置属性绑定到特定的bean(例子).
spring boot的配置属性读取顺序为:
 Devtools global settings properties on your home directory (~/.spring-boot-devtools.properties when devtools is active).
 @TestPropertySource annotations on your tests.
 @SpringBootTest#properties annotation attribute on your tests.
 Command line arguments.
 Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property)
 ServletConfig init parameters.
 ServletContext init parameters.
 JNDI attributes from java:comp/env.
 Java System properties (System.getProperties()).
 OS environment variables.
 A RandomValuePropertySource that only has properties in random.*.
 Profile-specific application properties outside of your packaged jar (application-{profile}.properties and YAML variants)
 Profile-specific application properties packaged inside your jar (application-{profile}.properties and YAML variants)
 Application properties outside of your packaged jar (application.properties and YAML variants).
 Application properties packaged inside your jar (application.properties and YAML variants).
 @PropertySource annotations on your @Configuration classes.
 Default properties (specified using SpringApplication.setDefaultProperties).
  因为spring-boot主要使用的application.properties/yaml文件,所以后面主要关注这个文件.
此外,spring代码中使用了大约近千个(300多类)默认值,这些默认值都是可以覆盖的.只需你在你的propeties/yaml文件中用相同的key即可.
所有的参考值见: example application.properties
application.properties SpringApplication loads properties from application.properties files in the following locations and adds them to the Spring Environment:
 A /config subdirectory of the current directory
 The current directory
 A classpath /config package
 The classpath root
  application.yml yaml是json的超集,相比properties文件,有着简洁灵活的优势 例如可以设置数组,设置group概念等.
yaml文件可以配置数组:
# 数组功能,等价 # my.servers[0]=dev.bar.com # my.servers[1]=foo.bar.com my: servers: - dev.bar.com - foo.bar.com #上面的配置可以通过注解绑定到以下bean中,非常强大. @ConfigurationProperties(prefix=&amp;#34;my&amp;#34;) public class Config { private List&amp;lt;String&amp;gt; servers = new ArrayList&amp;lt;String&amp;gt;(); } # 在一个yaml文件设置不同的profile配置,properties文件只能通过拆分文件`application-profiles.properties`实现. server: address: 192.168.1.100 --- spring: profiles: DEV server: address: 127.0.0.1 --- spring: profiles: PRD server: address: 192.168.1.120 yaml缺点:  YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file.
 当然使用properties文件缺点也明显,不能分组(yaml的&amp;mdash;功能);同时中文显示容易unicode码.
读取配置文件 除了application.properties文件,其他的配置属性文件需要我们自己加载读取.注意,下面的PropertySource无法加载yaml文件.
使用PropertySource cron=0/3 * * * * ?@Configuration @PropertySource(&amp;#34;classpath:foo.properties&amp;#34;) public class PropertiesWithJavaConfig { @Value(${cron}) private String cron; } //or @PropertySource({ &amp;#34;classpath:persistence-${envTarget:mysql}.properties&amp;#34; }) //multi files //java 8&#43; @PropertySource(&amp;#34;classpath:foo.properties&amp;#34;) @PropertySource(&amp;#34;classpath:bar.properties&amp;#34;) public class PropertiesWithJavaConfig { //... } //java 6&#43; @PropertySources({ @PropertySource(&amp;#34;classpath:foo.properties&amp;#34;), @PropertySource(&amp;#34;classpath:bar.properties&amp;#34;) }) public class PropertiesWithJavaConfig { //... } //通过xml加载 //register file in xml &amp;lt;context:property-placeholder location=&amp;#34;classpath:foo.properties&amp;#34; /&amp;gt; //foo.properties in src/main/resources &amp;lt;context:property-placeholder location=&amp;#34;classpath:foo.properties, classpath:bar.properties&amp;#34;/&amp;gt; 如何加载自定义的yaml文件 上面提到spring会默认加载application.yml文件的配置.但是其他文件名的yml文件无法通过@PropertySource加载.可以有以下方法.
 使用xml,然后在Java Config类加载xml. 个人不推荐使用xml文件,脱离spring boot的初衷了.
 使用yml加载器: The YamlPropertiesFactoryBean will load YAML as Properties and the YamlMapFactoryBean will load YAML as a Map.
 避免使用,尽量将你的所以配置放在application.yml里面,因为yml可以有分组功能.
 将你文件命名为application-redis.yml,然后在application.yml使用spring.profiles.include: &#39;redis&#39; 加载.
  使用yaml文件的加载可以通过ConfigurationProperties绑定到配置bean中.还要添加2个注解注册到spring:
@Configuration @EnableConfigurationProperties @ConfigurationProperties public class YAMLConfig { private String name; private String environment; private List&amp;lt;String&amp;gt; servers = new ArrayList&amp;lt;&amp;gt;(); // standard getters and setters }spring: profiles: prod name: prod-YAML environment: production servers: - www.abc.com - www.xyz.com profiles 很多配置希望基于环境,spring boot支持application-profile.properties格式的配置,profile可以是DEV,ST,UAT,PRD,TEST等.
例如某个class希望只有在PRD环境才有:
@Profile(&amp;#34;PRD&amp;#34;) @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter {} 然后在application.yml/properties设置profile:
spring: profiles: active: PRD properties文件设置profile application.properties文件只能使用application-DEV.properties,application-ST.properties设置profile.
yml文件设置profile application.yml既可以像properties文件使用application-DEV.yml来设置profile,也可以使用---分组.如下示例,logging.level=INFO在所有profile中生效,而在生产环境中增加日志文件设置,DEV环境则使用DEBUG级别日志.
# application.yml logging: level: root: INFO --- spring: profiles: DEV logging: level: root: DEBUG --- spring: profiles: PRD logging: path: /tmp/ file: BookWorm.log level: root: WARN 激活profiles 在application.yml/properties文件中激活某个profile:
spring: profiles: active: DEV 如果你设置了SPRING_PROFILES_ACTIVE环境变量,那么会覆盖上面的profile设置.当然你也可以使用自定义环境变量和默认值:
spring: profiles: active: ${ENV_TYP:PRD} # 读取ENV_TYP环境变量的值作为激活profile,如果没用这个环境变量,那么设置为PRD. 测试 </content>
    </entry>
    
     <entry>
        <title>Pattern Matching Anonymous Function</title>
        <url>https://xiongdahu.github.io/post/pattern-matching-anonymous-function/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>scala</tag>
        </tags>
        <content type="html"> Scala中很多使用if的地方都可以用match case来替换.常见的就是下面的这种写法:
val res = msg match { case it if it.contains(&amp;#34;H&amp;#34;) =&amp;gt; &amp;#34;Hello&amp;#34; case _ =&amp;gt; &amp;#34;Other&amp;#34; } //更常见的用法是去匹配参数的模式: case class Player(name: String, score: Int) def message(player: Player) = player match { case Player(_, score) if score &amp;gt; 100000 =&amp;gt; &amp;#34;Get a job, dude!&amp;#34; case Player(name, _) =&amp;gt; &amp;#34;Hey, $name, nice to see you again!&amp;#34; } def printMessage(player: Player) = println(message(player)) 其实case还有一种在匿名函数中的用法,看如下的代码,在词频统计或者过滤中很常见:
val wordFrequencies = (&amp;#34;habitual&amp;#34;, 6) :: (&amp;#34;and&amp;#34;, 56) :: (&amp;#34;consuetudinary&amp;#34;, 2) :: Nil def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter(wf =&amp;gt; wf._2 &amp;gt; 3 &amp;amp;&amp;amp; wf._2 &amp;lt; 25).map(_._1) 上面的代码有比较大的问题是访问tuple元素的方式比较难看,Scala提供了一种pattern matching anonymous function解决这个问题:
def wordsWithoutOutliers(wordFrequencies: Seq[(String, Int)]): Seq[String] = wordFrequencies.filter { case (_, f) =&amp;gt; f &amp;gt; 3 &amp;amp;&amp;amp; f &amp;lt; 25 } map { case (w, _) =&amp;gt; w } 注意到省略了最早版本的 wf =&amp;gt;,IDEA其实会提示你省略这个冗余部分.
另一个问题就是上面的操作中我们先过滤想要的序列,然后对序列进行了map映射操作.Scala 集合的 API 有一个叫做 collect 的方法，对于 Seq[A] ，它有如下方法签名：
def collect[B](pf: PartialFunction[A, B]): Seq[B] 这个方法将给定的偏函数(partial function) 应用到序列的每一个元素上， 最后返回一个满足条件并处理后新的序列 ,这里偏函数做了 filter 和 map 要做的事情。
现在，我们来重构 wordsWithoutOutliers ，首先定义需要的偏函数：
val pf: PartialFunction[(String, Int), String] = { case (word, freq) if freq &amp;gt; 3 &amp;amp;&amp;amp; freq &amp;lt; 25 =&amp;gt; word } wordFrequencies.collect(pf) 我们为这个案例加入了 _守卫语句_，不在区间里的元素就没有定义。
以上来自Scala初学者指南
当然有中文版:Scala初学者指南-gitbook
</content>
    </entry>
    
     <entry>
        <title>Scala Type Class</title>
        <url>https://xiongdahu.github.io/post/scala-type-class/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>scala</tag>
        </tags>
        <content type="html">  intro def insertionSort(xs: List[Int]): List[Int] = { def insert(y: Int, ys: List[Int]): List[Int] = ys match { case List() =&amp;gt; y :: List() case z :: zs =&amp;gt; if (y &amp;lt; z) y :: z :: zs else z :: insert(y, zs) } xs match { case List() =&amp;gt; List() case y :: ys =&amp;gt; insert(y, insertionSort(ys)) } } 假设有个排序算法如上，代码的第一个问题就是没有泛型，只能对Int排序。那如果改成insertionSort[T](xs: List[T]): List[T]显然不行，因为只有Number类型才有y &amp;lt; z方法。为了让这个函数实现多态（polymorphic ），需要将y &amp;lt; z这部分参数化。修改函数形式：
def insertionSort[T](xs: List[T])(lessThan: (T, T) =&amp;gt; Boolean) = { def insert(y: T, ys: List[T]): List[T] = ys match { //...omit some lines  case z :: zs =&amp;gt; if (lessThan(y, z)) y :: z :: zs else … } xs match { //...omit some lines  case y :: ys =&amp;gt; insert(y, insertionSort(ys)(lessThan)) } } 这样可以对任意类型排序，只要你提供排序方法lessThan.例如：
val fruits = List(&amp;#34;apple&amp;#34;, &amp;#34;pear&amp;#34;, &amp;#34;orange&amp;#34;, &amp;#34;pineapple&amp;#34;) insertionSort(fruits)((x: String, y: String) =&amp;gt; x.compareTo(y) &amp;lt; 0) 既然lessThan方法如此重要，我们定义一个trait:
trait Ordering[A]{ def lessThan(x:A,y:A):Int } 然后排序函数接受一个Ordering实例进行排序：
def insertionSort[T](xs: List[T])(ord: Ordering[T]): List[T] = { def insert(y: T, ys: List[T]): List[T] = ys match { case List() =&amp;gt; y :: List() case z :: zs =&amp;gt; if (ord.lessThan(y, z)) y :: z :: zs else z :: insert(y, zs) } xs match { case List() =&amp;gt; List() case y :: ys =&amp;gt; insert(y, insertionSort(ys)(ord)) } } 现在这个排序函数比较完美了，如果借助隐式参数，那么调用可以更简洁：
def insertionSort[T](xs: List[T])(implicit ord: Ordering[T]): List[T] = { def insert(y: T, ys: List[T]): List[T] = ys match { case List() =&amp;gt; y :: List() case z :: zs =&amp;gt; if (ord.lessThan(y, z)) y :: z :: zs else z :: insert(y, zs) } xs match { case List() =&amp;gt; List() case y :: ys =&amp;gt; insert(y, insertionSort(ys)) } } //implicit val for insertionSort function implicit val stringOrdering: Ordering[String] = new Ordering[String] { def lessThan(x: String, y: String): Boolean = x.compareTo(y) &amp;lt; 0 } val fruits = List(&amp;#34;apple&amp;#34;, &amp;#34;pear&amp;#34;, &amp;#34;orange&amp;#34;, &amp;#34;pineapple&amp;#34;) insertionSort(fruits) insertionSort(fruits)的调用形式看上去不够优雅（不够OO),我们希望调用的形式是：fruits.insertionSort 得到排序后的list。通过之前文章的隐式转换很容易想到，我们需要将insertionSort方法作为一个implicit class的方法，这样即可通过隐式转换得到fruits.insertionSort:
//1. 注意原函数的参数改为class参数传入 //2. 由于原函数用了递归，所以这里加了一层函数 implicit class FruitOps[T](list: List[T])(implicit ord: Ordering[T]) { def insertionSort(): List[T] = { insertSortInternal(list)(ord) } def insertSortInternal[T](xs: List[T])(implicit ord: Ordering[T]): List[T] = { def insert(y: T, ys: List[T]): List[T] = ys match { case List() =&amp;gt; y :: List() case z :: zs =&amp;gt; if (ord.lessThan(y, z)) y :: z :: zs else z :: insert(y, zs) } xs match { case List() =&amp;gt; List() case y :: ys =&amp;gt; insert(y, insertSortInternal(ys)) } } } // val fruits = List(&amp;#34;apple&amp;#34;, &amp;#34;pear&amp;#34;, &amp;#34;orange&amp;#34;, &amp;#34;pineapple&amp;#34;) fruits.insertionSort //List(pear, apple, orange, pineapple) type class 类型参数化和隐式参数结合即scala的type class，实现在不修改原有代码的前提下对type(这里是List[String])增加行为和属性。例如，已有类型Person，想要增加一个print方法实现打印个人简历。如果通过继承，那么Person代码会被改变，且print方法不能随意替换。如果通过Printer工具类同样Person只能有一种print实现（或者多个Printer工具类）。通过type class和，可以实现person.print的调用格式，且print的具体实现是由当前scope的implicit type class instance决定，在不同的scope可以通过提供不同的type class实例达到不同的print效果。
type class由3部分组件：
 type class：a trait with type parameter,即Ordering[T]
 type class instance: 即上面的val stringOrdering: Ordering[String]，一般为implicit
 interface for user: 即上面的FruitOps，是一个implicit class.
  one more example class Person(val name: String, val address: String) //type class trait HtmlWriter[A] { def write(data: A): String } // a type class instance implicit object PersonWriter extends HtmlWriter[Person] { override def write(data: Person): String = { s&amp;#34;&amp;lt;span&amp;gt;${data.name}and ${data.address}&amp;lt;/span&amp;gt; &amp;#34; } } // type class interface for user implicit class HtmlUtil[A](data:A){ def toHtml(implicit writer: HtmlWriter[A]):String={ writer.write(data) } } val p = new Person(&amp;#34;xiongdahu&amp;#34;,&amp;#34;beijing&amp;#34;) p.toHtml</content>
    </entry>
    
     <entry>
        <title>Scala Notes</title>
        <url>https://xiongdahu.github.io/post/scala-notes/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag>
        </tags>
        <content type="html">  scala-notes some notes on scala, includes:
setup with maven
 import
 == and eq
 case class
 for&amp;hellip;yield
 companion object and class
 method and function(def val)
 _ in scala
 =&amp;gt; in scala
 () {} in scala
 implicit
 string
  setup with maven 目前用sbt的项目比较少,maven的更多. 而且sbt烧cpu. maven项目使用scala参考我的gist:scala_maven_pom.xml
学习scala可以使用scala插件的worksheet,这是一个基于脚本互动的REPL. 本文后面的代码全部在worksheet中测试.
import scala的import语句很灵活，可以在任何地方导入class内部外部，方法内部，代码块内部，这样做有一个好处，限制导入方法和对象的scope，防止污染变量。在后面学了implicit隐式转换后，就知道import scope有多重要了。
import scala.math._ // import everything in math package import java.util.{ ArrayList =&amp;gt; _, _} //第一个下划线表示隐藏ArrayList，第二个表示通配符，导入所有  //默认，scala导入: java.lang._ scala._ scala.Predef._ //推荐看一下Predef的源代码包括： //Predef中定义的方法和属性 //常用方法和类 //打印方法 println等 //一些调试和错误方法 //一个特殊的方法表示方法未实现 def ??? : Nothing = throw new NotImplementedError //Predef还有大量的隐式转换和隐式参数 == and eq scala里面==等价于java的equals方法即内容比较,并且可以正确处理null(还记得java规范里面烦人的 &amp;quot;A&amp;quot;.equals(m)规范么?). 而地址(应用)比较使用eq 方法,这个方法其实很少用到,应用代码一般无需比较2个变量的地址.
case class case class类似data class,即java的pojo bean,但是提供了更多的方法.
// 5个特性 // 1.添加companion object,apply方法,unapply方法 // 2.toString, hashCode and equals and copy methods case class Student(name: String, marks: Int) val s1 = Student(&amp;#34;Rams&amp;#34;, 550) val s2 = s1.copy() val s3 = s1.copy(marks = 590) s2 == s1 //true s3 == s1 //false  // 3. 构造函数参数自动成为成员变量,即自动给构造参数添加val前缀 // 4. 可以用于模式匹配 // 5. 默认的,case class和case object是可序列化的(实现Serializable),也即是可以网络传输的 for&amp;hellip;yield  Scala’s “for comprehensions” are syntactic sugar for composition of multiple operations with foreach, map, flatMap, filter or withFilter
scala的for推导其实就是组合多个foreach, map, flatMap, filter or withFilter的语法糖.
以下代码结果r1,r2完全一致:
 val c1 = List(1, 2, 3) val c2 = List(&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;c&amp;#34;) val c3 = List(&amp;#34;!&amp;#34;, &amp;#34;@&amp;#34;, &amp;#34;#&amp;#34;) val r1 = for (x &amp;lt;- c1; y &amp;lt;- c2; z &amp;lt;- c3) yield { x &#43; y &#43; z } //&amp;lt;==&amp;gt; val r2 = c1.flatMap(x =&amp;gt; c2.flatMap(y =&amp;gt; c3.map(z =&amp;gt; { x &#43; y &#43; z }))) assert(r1 == r2)//true companion object Scala中，除了方法，一切都是对象！函数也是对象,根据参数的个数,函数的类型为FunctionN.N为函数参数个数.
伴生对象用于定义一些静态方法(工厂方法),其中apply和unapply方法常用. apply方法用于代替new的工厂方法.
同时,companion objects can access private fields and methods of their companion trait/class.
class Person(name: String, age: Int) { private var skill: String = &amp;#34;no skill&amp;#34; def introduce() = println(s&amp;#34;my name is $name, I am $ageyears old&amp;#34;) } // companion object name should be identical to the class name. object Person { def apply(name: String, age: Int): Person = { new Person(name, age) } //apply method override  def apply(name: String, age: Int, skill: String): Person = { val p = new Person(name, age) p.skill = skill p } } val dahu = Person(&amp;#34;dahu&amp;#34;, 30) dahu.introduce 伴生对象在模式匹配和抽取器的应用
//关于抽取器和unapply方法的进一步示例: trait User class FreeUser( val name: String, val score: Int, val upgradeProbability: Double) extends User class PremiumUser( val name: String, val score: Int) extends User object FreeUser { def unapply(user: FreeUser): Option[(String, Int, Double)] = Some((user.name, user.score, user.upgradeProbability)) } object PremiumUser { def unapply(user: PremiumUser): Option[(String, Int)] = Some((user.name, user.score)) } val freeUsr = new FreeUser(&amp;#34;john&amp;#34;, 70, 0.5) freeUsr match { case FreeUser(name, _, p) =&amp;gt; if (p &amp;gt; 0.75) println(s&amp;#34;what can I do for you,$name&amp;#34;) else println(s&amp;#34;hello,$name&amp;#34;) case _ =&amp;gt; println(&amp;#34;who are you&amp;#34;) } //bool抽取器 object premiumCandidate { def unapply(user: FreeUser): Boolean = user.upgradeProbability &amp;gt; 0.4 } // bool抽取器的用法 freeUsr match { case freeUser@premiumCandidate() =&amp;gt; println(s&amp;#34;恭喜成为黄金会员候选人&amp;#34;) case _ =&amp;gt; println(&amp;#34;欢迎回来&amp;#34;) } //来源: [Scala初学者指南](http://danielwestheide.com/scala/neophytes.html) method and function(def val) 先看函数定义
 A function can be invoked with a list of arguments to produce a result.
A function has a parameter list, a body, and a result type. Functions that are
members of a class, trait, or singleton object are called methods.
Functions defined inside other functions are called local functions. Functions
with the result type of Unit are called procedures. Anonymous functions in
source code are called function literals. At run time, function literals are
instantiated into objects called function values.
quote from：Martin Odersky - Lex Spoon - Bill Venners
 函数由一个参数列表，一个函数体，一个结果类型构成。函数如果作为class，trait或者object（注意，这里的object是scala特有的单例对象，不是Java中的instance）的成员，那么这个函数叫方法。函数和方法的区别就是函数时FunctionN的一个实例,编译后是一个单独的class文件,而方法是依附对象的,调用方法的格式是obj.method(param),而调用函数的格式本质是将调用函数对象的apply方法.
函数定义在别的函数内部叫局部函数。函数返回值是Unit称为过程（procedures）。
匿名函数是通过函数字面量（ ()=&amp;gt;{函数体} ）定义的函数。在运行时，函数字面量被实例化对象，叫函数值。
函数和方法的区别，大部分情况下不用在意区别：
函数是有类型的： (T1, &amp;hellip;, Tn) =&amp;gt; U，是trait FunctionN的一个实例对象，函数有一个apply方法，用来实际执行function的函数体。函数还有toString， andThen ，conpose等方法。
val fn: Int =&amp;gt; String = i =&amp;gt; i&#43;&amp;#34;123&amp;#34; //声明一个函数 fn(3) //实际背后是fn.apply(3); scala中除了method，一切都是instance
method只能用def 声明，function可以是val和def声明
method可以有类型参数[] ,function不能有，函数在声明时就需要知道具体类型。
def fn(p: List[String]): Map[T] = {...} //is function def m[T](t: List[T]): Map[T] = {...} //is method,可以有泛型参数.  将method转换成function有两种方法： val f1 = m1 _ //下划线表示参数列表 eta-expansion val f2: (Int) =&amp;gt; Int = m1 //m1 的入参和返回值要和f2的一样  //scala可以自动将method转换为function，如果一个方法需要一个函数作为参数， //那么可以直接将m1传递给他，不需要 下划线。 //每一次将方法转换成function都是得到一个新的function object。 //function既然是一个instance，那么编译成class文件会有一个class文件。 _ in scala /** * class Reference[T] { * private var contents: T = _ * //使用类型默认值初始化变量，如果T是Int，则contents是0，T是boolean，则是false；Unit则是() * } * * * List(1, 2, 3) foreach (print _ ) //output 123，表示实参 * * //在匿名函数中作为参数占位符： * List(1, 2, 3) map ( _ &#43; 2 ) * // _ &#43; 2是一个匿名函数 * * //模式匹配中的最后一行作为通配符 * case _ =&amp;gt; &amp;#34;this is match anything other than before cases &amp;#34; * * expr match { * * case List(1,_,_) =&amp;gt; &amp;#34; a list with three element and the first element is 1&amp;#34; * case List(_*) =&amp;gt; &amp;#34; a list with zero or more elements &amp;#34; * case Map[_,_] =&amp;gt; &amp;#34; matches a map with any key type and any value type &amp;#34; * case _ =&amp;gt; * } * * * //import中作为通配符和隐藏符 * import java.util.{ ArrayList =&amp;gt; _, _} * //第一个下划线表示隐藏ArrayList，第二个表示通配符，导入所有 * * //将方法变为value * method _ // Eta expansion of method into method value * * //tuple 的访问 * tpl._2 //返回tpl第二个元素，注意，tuple是从1开始的 * * * //还有很多高级的概念，目前还不理解，so上给出的答案 * def f[M[_]] // Higher kinded type parameter * def f(m: M[_]) // Existential type * _ &#43; _ // Anonymous function placeholder parameter * m _ // Eta expansion of method into method value * m(_) // Partial function application * _ =&amp;gt; 5 // Discarded parameter * case _ =&amp;gt; // Wild card pattern -- matches anything * val (a, _) = (1, 2) // same thing * for (_ &amp;lt;- 1 to 10) // same thing * f(xs: _*) // Sequence xs is passed as multiple parameters to f(ys: T*) * case Seq(xs @ _*) // Identifier xs is bound to the whole matched sequence * var i: Int = _ // Initialization to the default value * def abc_&amp;lt;&amp;gt;! // An underscore must separate alphanumerics from symbols on identifiers * t._2 */ =&amp;gt; in scala 函数字面量分隔参数和函数体 在函数字面量中 =&amp;gt;分隔参数和函数体. 也可以表示一个函数类型.
(x: Int) =&amp;gt; x * 2表示一个匿名函数，接收一个整数，返回参数乘以2的结果。 scala&amp;gt; val f: Function1[Int,String] = argInt =&amp;gt; &amp;#34;my int: &amp;#34;&#43;argInt.toString f: Int =&amp;gt; String = &amp;lt;function1&amp;gt; // Int =&amp;gt; String 等价 Function1[Int,String] scala&amp;gt; val f2: Int =&amp;gt; String = myInt =&amp;gt; &amp;#34;my int v2: &amp;#34;&#43;myInt.toString f2: Int =&amp;gt; String = &amp;lt;function1&amp;gt; //注意，匿名函数没有参数也要括号 ()=&amp;gt;{}； //() =&amp;gt; Unit表示没有返回值的函数 call-by-name parameter 在函数的参数声明中使用=&amp;gt;(e.g. def f(arg: =&amp;gt; T))表示这个参数是&amp;raquo;by-name parameter&amp;raquo;,表示这个参数只有在函数体中包含这个参数的语句被执行才会被evaluate。
这个特点叫call-by-name,arg可以是一个代码块，甚至函数，在传递给f时不会evaluate，只有f函数体内部调用arg时，arg才会被执行。
scala&amp;gt; def now()={println(&amp;#34;nano time:&amp;#34;);System.nanoTime} scala&amp;gt; def callByName(p: =&amp;gt; Long):Long = {println(&amp;#34;call-by-name:&amp;#34;&#43;p);p;} callByName: (p: =&amp;gt; Long)Long scala&amp;gt; def justCall(p : Long) :Long = {println(&amp;#34;just-call:&amp;#34;&#43;p);p;} justCall: (p: Long)Long scala&amp;gt; callByName(now()) nano time: call-by-name:5664511571389 nano time: res2: Long = 5664511727048 //now()在callByName的函数体的每个出现的地方都执行了  scala&amp;gt; justCall(now()) nano time: just-call:5667489483159 res3: Long = 5667489483159 //now()只在传递参数的时候被执行了. 模式匹配中分隔case模式和返回值 在case语句中，=&amp;gt; 分隔模式和返回表达式。
var a = 1 a match{ case 1 =&amp;gt; println(&amp;#34;One&amp;#34;) case 2 =&amp;gt; println(&amp;#34;Two&amp;#34;) case _ =&amp;gt; println(&amp;#34;No&amp;#34;) } () {} in method call // 规则1:{}表示code block,你可以在里面放几乎任何语句,block的返回值是由最后一句决定 // 规则2:block内容如果只有一句可以省略{},但是case clause除外:{case ...} // 规则3: 单参数方法如果实参是code block,那么可以省略() { import util.Try println{&amp;#34;hello&amp;#34;} 5 } val tupleList = List[(String, String)]() //规则2 tupleList takeWhile( { case(t1,t2) =&amp;gt; t1==t2 } ) // 规则2 List(1, 2, 3).reduceLeft(_&#43;_) // 一种特殊情况,提示:隐式转换 val r = List(1, 2, 3).foldLeft(0) {_&#43;_} //val l = r{&amp;#34;hello&amp;#34;}  //不要调用这个方法 def loopf(x: Int): Int = loopf {x} //使用{}的特殊情况:for推导可以和()互换,一般建议是除了yield的其他情况都用() for{tpl &amp;lt;-tupleList} yield tpl._2 //不建议 for{tpl &amp;lt;-tupleList} { println(tpl) } //推荐 for(tpl &amp;lt;-tupleList) { println(tpl) } //补充, 方法定义时如果没有返回值可以省略=,称为procedure,scala 2.13已经废弃,不要这么写 //don&amp;#39;t def p(in:String ){ println(s&amp;#34;hello $in&amp;#34;) } implicit implicit分为隐式参数和隐式转换方法.
隐式参数 //1.隐式参数 class Prefixer(val prefix: String) def addPrefix(s: String)(implicit p: Prefixer) = p.prefix &#43; s // addPrefix需要提供一个隐式实际参数,否则报错.当然可以在调用时显式传递一个参数 implicit val myImplicitPrefixer = new Prefixer(&amp;#34;***&amp;#34;) addPrefix(&amp;#34;abc&amp;#34;) // returns &amp;#34;***abc&amp;#34; 隐式转换 //1. 定义一个含有目标方法的class class BlingString(s:String) { def bling = &amp;#34;*&amp;#34;&#43;s&#43;&amp;#34;*&amp;#34; } //2. 定义隐式转换方法 implicit def str2BlingString(s:String) = new BlingString(s) //3. 使用目标方法 val s = &amp;#34;hello&amp;#34; s.bling // *hello*  //在scala.Predef中定义了大量的隐式转换,例如RichInt,StringOps这些,提供类似mkString这些方法 //太阳底下无新事,scala常用对象的灵活丰富的语法都是通过隐式转换添加的. implicit class 可以看到上面的第1,2步非常的繁琐，于是SIP-13提出一个implicit class,将上面的2步合并:
implicit class BlingString(s:String) { def bling = &amp;#34;*&amp;#34;&#43;s&#43;&amp;#34;*&amp;#34; } //implicit def str2BlingString(s:String) = new BlingString(s)  val hi = &amp;#34;hello&amp;#34; hi.bling // *hello* 注意，这个只是一个语法糖。去糖后就是上面的那个形式。 implicit class有3个约束和一个注解问题：
 必须要有主一个构造函数且只能一个构造参数（implicit参数除外）。构造参数就是源类型. 这个构造函数即等价上面第2步的隐式转换方法：
implicit class RichDate(date: java.util.Date) // OK! implicit class Indexer[T](collecton: Seq[T], index: Int) // BAD! implicit class Indexer[T](collecton: Seq[T])(implicit index: Index) // OK!  只能定义在其他trait/class/object中：
  object Helpers { implicit class RichInt(x: Int) // OK! } implicit class RichDouble(x: Double) // BAD! 在当前scope内，不允许有和implicit class同名的方法，对象，变量。因为case class会自动生成同名object对象，所以implicit class不能是case class。
object Bar implicit class Bar(x: Int) // BAD!  val x = 5 implicit class x(y: Int) // BAD!  //cuz case class has companion object by default implicit case class Baz(x: Int) // BAD! conflict with the companion object  还有就是implicit class的注解在去语法糖后会自动添加到类和方法，除非在注解中指明范围：
  @bar implicit class Foo(n: Int) //desugar @bar implicit def Foo(n: Int): Foo = new Foo(n) @bar class Foo(n:Int) //除非在注解中指明：genClass / method @(bar @genClass) implicit class Foo(n: Int) //desugar得到 @bar class Foo(n: Int) implicit def Foo(n: Int): Foo = new Foo(n)  value class scala 还有一个概念：value class
class Wrapper(val underlying: Int) extends AnyVal //1. 一个public val参数表示runtime类型，这里是Int. 编译时是Wrapper类型，所以value class目的是降低分配开销。 //2. value class 需要 extends AnyVal //3. value class 只能有 defs, 不能有vals, vars, or nested traits, classes or objects， // 因为def是通过静态方法实现的，而val，var这些则必须创建相应类型了。 //4. value class 只能扩展通用trait（universal traits）， // universal traits是A universal trait is a trait that extends Any, only has defs as members, and does no initialization. // extension method 当implicit class类型参数是AnyVal子类时，value class和上面的implicit class形式相近，所以可以通过value class降低implicit class的分配开销。例如RichtInt
implicit class RichInt(val self: Int) extends AnyVal { def toHexString: String = java.lang.Integer.toHexString(self) } 因为RichInt是value class，在运行时（runtime）不会有RichInt这个类，而是Int，而3.toHexString实际是通过静态方法实现的： RichInt$.MODULE$.extension$toHexString(3),这么做好处是减少对象分配开销(avoid the overhead of allocation)。如果implicit class的类型参数不是AnyVal子类，那么在runtime时会有相应类型对象被创建，用户察觉不到区别。
value class还有其他作用和局限性，可以参考上面链接。如果发现错误，请指出，先谢过。
Implicit Design Patterns in Scala​www.lihaoyi.com
The Neophyte&amp;rsquo;s Guide to Scala​
集合类的implicit转换 //scala集合和java集合的转换是scala编程最常用的,毕竟java有大量第三方库. //scala提供了两种方法,第一种方法就是隐式转换collection.JavaConversions(scala 2.8) //很快意识到隐式转换对于使用者的代码阅读比较复杂,在2.8.1提供了显示转换collection.JavaConverters, //先看JavaConversions隐式转换: object JavaConversions extends WrapAsScala with WrapAsJava //在WrapAsJava  implicit def mapAsJavaMap[A, B](m: Map[A, B]): ju.Map[A, B] = m match { case null =&amp;gt; null case JMapWrapper(wrapped) =&amp;gt; wrapped.asInstanceOf[ju.Map[A, B]] case _ =&amp;gt; new MapWrapper(m) } //然后看下collection.JavaConverters._,稍微复杂一些,但是换汤不换药,底层还是隐式转换, object JavaConverters extends DecorateAsJava with DecorateAsScala //在DecorateAsJava中有很多隐式转换方法,这些方法将scala集合转换为AsJava对象 //(注意下面的ju,是java.util缩写,详情见[征服scala_1](https://zhuanlan.zhihu.com/p/22670426)) implicit def seqAsJavaListConverter[A](b : Seq[A]): AsJava[ju.List[A]] = new AsJava(seqAsJavaList(b)) // 而AsJava中定义了asJava方法,这样我们就可以在scala集合上面调用asJava class AsJava[A](op: =&amp;gt; A) { /** Converts a Scala collection to the corresponding Java collection */ def asJava: A = op } //并且asJava方法的实现是作为构造参数传入AsJava的 //上面的seqAsJavaList就是将scala.Seq转换为ju.List的具体实现 def seqAsJavaList[A](s: Seq[A]): ju.List[A] = s match { case null =&amp;gt; null case JListWrapper(wrapped) =&amp;gt; wrapped.asInstanceOf[ju.List[A]] case _ =&amp;gt; new SeqWrapper(s) } //综上,JavaConverters用的还是隐式转换,只不过增加了一个中间类AsJava/AsScala. 隐式转换的scope //无论是隐式参数还是隐式转换,编译器都要知道去哪里查找这些implicit参数或者方法, //例如import collection.JavaConverters._ //由于scala import可以出现在任何地方,这为控制implicit的scope提供了灵活性 //这一块我不是完全清楚,只提供一个自己的理解 // 1.首先是当前scope的Implicits定义,例如,当前方法内,class内 // 2.显式导入 import collection.JavaConversions.asScalaIterator // 3.通配符导入 import collection.JavaConverters._ // 4.类型的伴生对象内(这个常用) // 5.参数类型的隐式scope (2.9.1添加):class构造参数的隐式转换搜索返回会被应用到 class A(val n: Int) { def &#43;(other: A) = new A(n &#43; other.n) } object A { implicit def fromInt(n: Int) = new A(n) } new A(1) &#43; 2 // new A(1) &#43; A.fromInt(2) //6.类型参数的隐式转换,下面的sorted方法期望有一个Ordering[A], //在伴生对象中提供了一个 A -&amp;gt; Ordering[A] , class A(val n: Int) object A { implicit val ord = new Ordering[A] { def compare(x: A, y: A) = implicitly[Ordering[Int]].compare(x.n, y.n) } } List(new A(5), new A(2)).sorted // 注意implicitly[Ordering[Int]] 表示在当前scope内搜索一个隐式参数值 def implicitly[T](implicit e: T): T = e string // The s String Interpolator: val name = &amp;#34;James&amp;#34; println(s&amp;#34;Hello, $name&amp;#34;) // Hello, James  // The f Interpolator val height = 1.9d val name = &amp;#34;James&amp;#34; println(f&amp;#34;$name%s is $height%2.2f meters tall&amp;#34;) // James is 1.90 meters tall  // The raw Interpolator // The raw interpolator is similar to the s interpolator except that // it performs no escaping of literals within the string. // Here’s an example processed string // 即不翻译转义字符 scala&amp;gt;raw&amp;#34;a\nb&amp;#34; res1: String = a\nb // &amp;#34;&amp;#34;&amp;#34; triple quotes string // triple quotes &amp;#34;&amp;#34;&amp;#34; to escape characters val donutJson4: String = &amp;#34;&amp;#34;&amp;#34; |{ |&amp;#34;donut_name&amp;#34;:&amp;#34;Glazed Donut&amp;#34;, |&amp;#34;taste_level&amp;#34;:&amp;#34;Very Tasty&amp;#34;, |&amp;#34;price&amp;#34;:2.50 |} &amp;#34;&amp;#34;&amp;#34; .stripMargin // |会被忽略 // &amp;#34;&amp;#34;&amp;#34;还有个很好的用处,正则表达式: // 在java中表示一个或多个空格,&amp;#34;\\s&#43;&amp;#34; // 在scala中只要 &amp;#34;&amp;#34;&amp;#34;\s&#43;&amp;#34;&amp;#34;&amp;#34;,对于复杂正则表达式非常有用. links https://www.btbytes.com/scala.html
https://booksites.artima.com/programming_in_scala_2ed/examples/index.html
http://blog.higher-order.com/assets/fpiscompanion.pdf
https://courses.cs.washington.edu/courses/cse341/09au/notes/scala.html
https://github.com/dnvriend/my-scala-notes
https://gist.github.com/jamesyang124/d65b067327452792287a
</content>
    </entry>
    
     <entry>
        <title>使用redis的hash优化内存使用</title>
        <url>https://xiongdahu.github.io/post/%E4%BD%BF%E7%94%A8redis%E7%9A%84hash%E4%BC%98%E5%8C%96%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/</url>
        <categories>
          <category>翻译</category>
        </categories>
        <tags>
          <tag>code</tag><tag>redis</tag>
        </tags>
        <content type="html">  原文 Understanding Redis hash-max-ziplist-entries
问题和方案 场景: 有3亿张图片放在对象存储(DELL ECS/AMAZON EC2)上面,现在需要保存图片的id-&amp;gt;用户id的映射.最直接的思路是:
set &amp;#34;media:1155220&amp;#34; &amp;#34;user1&amp;#34; set &amp;#34;media:1155221&amp;#34; &amp;#34;user2&amp;#34; 这样设计key之后3亿张图片需要21GB的内存,因为redis的string是线性增长的.
此时可以使用hash优化内存使用.hash是类似java hashmap的数据结构: key field1 value1 field2 value2 &amp;hellip;
hash的强大在于它可以只获取一个field的value,而无需返回整个key.
再仔细想想,hash的key可以类比于分库分表的bucket概念.
回到上面的问题,Mike Krieger,Instagram的创始人提出将图片的id除以1000分片(sharding)到1000个hash key上:
HSET &amp;#34;mda-bkt:1155&amp;#34; &amp;#34;1155220&amp;#34; &amp;#34;user1&amp;#34; &amp;#34;1155221&amp;#34; &amp;#34;user2&amp;#34; # mda-bkt:1155 是1155220/1000之后得到的bucket. HGET &amp;#34;mda-bkt:1155&amp;#34; &amp;#34;1155220&amp;#34; # 这里key的前缀*mda-bkt:)只重复了1000次,而上面的string方式重复了3亿次. 因为redis针对hash list zset三种结构使用了ziplist高效存储方案.
新的问题又来了,redis对于ziplist结构的key数量有限制的,即hash-max-ziplist-entries的含义是: 可使用内部空间优化存储的最多hash key
使用ziplist的数据结构有三个list hash zset:
list-max-ziplist-entries 512 list-max-ziplist-value 64 #Limits for ziplist use with LISTs. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 #Limits for ziplist use with HASHes (previous versions of Redis used a different name and encoding for this) #hash-max-zipmap-entries 512 (for Redis &amp;lt; 2.6). zset-max-ziplist-entries 128 zset-max-ziplist-value 64 #Limits for ziplist use with ZSETs. 你可以使用debug_object(key)查看你的key是否使用了ziplist结构.
建议hash-max-ziplist-entries最大设置为1000,过大会影响redis性能.
参考资料 redis moemory optimize
9.1.1 The ziplist representation-EBOOK – REDIS IN ACTION
</content>
    </entry>
    
     <entry>
        <title>使用travis自动发布markdown到博客</title>
        <url>https://xiongdahu.github.io/post/%E4%BD%BF%E7%94%A8travis%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83markdown%E5%88%B0%E5%8D%9A%E5%AE%A2/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>github</tag>
        </tags>
        <content type="html"> github给个人和组织免费提供github pages功能. 就是说如果有个repo的名字为 xiongdahu.github.io (xiongdahu为你的github username), 那么这个repo里面的master或者gh-page分支的内容如果存在index.html, 那么其他人可以通过 https://xiongdahu.github.io 访问这个站点.
借助于一些static gen工具,你可以将你的markdown转换为一个静态网站(html,js,css). 然后把静态网站的内容上传到刚说的repo中, 就有一个自己的博客站点了. static gen工具非常多, github推荐的是Jekyll(ruby), 主流的还有hexo(js)和hugo(go), hexo因为是基于js的,所以高质量的主题多(因为做主题是需要js,css技能), hugo的编译快些, 但是好看的主题不多. 高质量的主题除了美观可能还需要考虑移动端(responsive),评论, 访问统计等各种功能. 每个gen工具都有自己的主题站点. hugo的主题在这里找: hugo themes.
制作github pages站点的一般做法是把代码(放图片和markdown)放在master分支,static gen编译后的(html,js,css,image)内容放在gh-pages分支.然后在settings里面设置. 这样就可以得到一个站点了. 这么做有个缺点,就是markdown文件会被别人整个下载过去,之前就遇到过一次. 正好github现在有3个免费私有仓库. 所以我把源码放在私有仓库xiongdahu.github.io.src里面,而编译后的内容发布的 https://xiongdahu.github.io上面去.
自动编译发布这个过程就是持续集成(continue integration,CI)了, 即我提交一个markdown文件,我的主页会自动看到这篇文章, 不需要我在本地编译再提交编译结果文件.travis-ci 提供了免费的github CI服务. 使用github账号登录就会有提示操作. 这里勾选私有仓库xiongdahu.github.io.src, 然后在项目里面添加.travis.yml文件告诉travis如何编译和发布内容到个人站点.
markdown渲染设置 hugo使用BlackFriday渲染markdown文件,默认的设置有几个过于严格:
 没有硬换行,需要使用\来表示换行
 标题和#之间必须有空格
 代码块前面必须有空行
  在config.toml可以修改这些配置:
# markdown解析引擎blackfriday配置,  # extensions : noEmptyLineBeforeBlock-代码块前面无需空行,hardLineBreak-换行无需使用backslash # extensionsmask spaceHeaders-标题之间无需空格 [blackfriday] angledQuotes = true extensions = [&amp;#34;hardLineBreak&amp;#34;,&amp;#34;noEmptyLineBeforeBlock&amp;#34;] extensionsmask = [&amp;#34;spaceHeaders&amp;#34;] fractions = false plainIDAnchors = true travis-ci配置 就是从一个私有的源码仓库编译,然后将编译后的文件强制覆盖到个人主页(即username.github.io这个仓库)的仓库中.具体的配置就不说了,注意是需要一个github的personal-access-key. 下面是.travis.yml内容:
dist: xenial language: python python: 3.7 # Handle git submodules yourself git: submodules: false # Use sed to replace the SSH URL with the public URL, then initialize submodules before_install: - sudo apt update -qq - sudo apt -yq install apt-transport-https - echo -e &amp;#34;Host github.com\n\tStrictHostKeyChecking no\n&amp;#34; &amp;gt;&amp;gt; ~/.ssh/config - git config --global user.email ${GITHUB_EMAIL} - git config --global user.name ${GITHUB_USERNAME} - sed -i &amp;#39;s/git@github.com:/https:\/\/github.com\//&amp;#39; .gitmodules - git submodule update --init --recursive install: # install latest hugo release version # - wget -qO- https://api.github.com/repos/gohugoio/hugo/releases/latest | sed -r -n &amp;#39;/browser_download_url/{/Linux-64bit.deb/{s@[^:]*:[[:space:]]*&amp;#34;([^&amp;#34;]*)&amp;#34;.*@\1@g;p;q}}&amp;#39; | xargs wget # use local hugo pkg for speed - sudo dpkg -i hugo*.deb - rm -rf public 2&amp;gt; /dev/null # compile src to dist script: - hugo -d ./dist/ after_success: - git clone https://xiongdahu:${GITHUB_TOKEN}@github.com/xiongdahu/xiongdahu.github.io.git - cd xiongdahu.github.io - git rm -rf . &amp;amp;&amp;amp; git clean -fxd - mv -v ../dist/* . - git add . - git commit -m &amp;#34;update site&amp;#34; - git remote set-url origin https://xiongdahu:${GITHUB_TOKEN}@github.com/xiongdahu/xiongdahu.github.io.git - git remote -v - git push -q -f 要点:
 在项目的源码中放了hugo的deb安装包,省去下载的过程
 主题以submodules放在themes目录中,所以编译前一定要git submodule update --init --recursive更新主题到本地.
 目标repo的远程仓库一定要在push前重新设置:git remote set-url origin xxx
 </content>
    </entry>
    
     <entry>
        <title>wsl-docker-environment</title>
        <url>https://xiongdahu.github.io/post/wsl-docker-environment/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>wsl</tag><tag>code</tag>
        </tags>
        <content type="html"> 使用wsl,MobaXterm,cmder,docker打造可视化的linux开发环境
离不开Windows的理由很多,作为后端开发需要使用linux的情况也很多,双系统总归是不方便,而且linux下的GUI体验也没用Win 10好. 如果使用虚拟机,那么文件交换和网络等各种问题也需要解决,对系统的内存要求也更高一些.微软为了让更多的开发人员留在Win10上面,开发了wsl功能.目前的实际体验已经很棒,今天介绍一下如何打造一个可视化的linux开发环境&amp;ndash;即在Win10启动linux的GUI软件,例如vs code等.在wsl启动vs code写代码可以有效避免一些Windows和linux的编码和换行问题.
本教程分为2部分:
配置wsl可视化
 在wsl使用docker
   以下内容中 wsl和ubuntu含义相同,console和命令行含义相同.
 配置wsl可视化 系统要求是Win 10 1803&#43;版本(低于1803的wsl功能有问题),必须是专业版或教育版才有wsl功能.以下内容的命令行如果开头有&amp;gt;字符请忽略.
windows开启wsl功能 控制面板\程序\程序和功能\开发或关闭Windows功能 &amp;gt; 勾选 &amp;lsquo;适用于linux的Windows子系统&amp;rsquo;和 &amp;lsquo;hyper-V&amp;rsquo;(docker for Windows需要这个功能,也可以使用virtualbox代替), 重启电脑.
windows下载wsl Windows store搜索&amp;raquo;wsl&amp;raquo;或者&amp;raquo;ubuntu&amp;raquo;下载ubuntu版本. ubuntu和ubuntu1804是一个版本,ubuntu1604是旧的版本.安装完成你的Windows应用列表会有一个ubuntu应用,点击图标即可打开ubuntu命令行.第一次启动需要等待初始化,然后设置用户名和密码.由于字体难看,所以不用这个自带的命令行而使用下面的cmder.
windws下载cmder软件 cmder是Windows下最强的命令行功能. 不要下载mini那个,里面没用vim和git.第一次启动cmder记得修改cmder启动目录(默认是c盘)和显示中文设置,具体方法请google.
wsl修改软件源,使用阿里云的源. &amp;gt; sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak &amp;gt; sudo sed -i &amp;#39;s/archive.ubuntu.com/mirrors.aliyun.com/g&amp;#39; /etc/apt/sources.list &amp;gt; sudo apt update &amp;gt; sudo apt upgrade -y wsl安装必要软件 # 安装你需要的软件,git和vim是必须的,后面的编辑命令是使用vim &amp;gt;sudo apt install openjdk-8-jdk-headless openjdk-8-jre-headless maven git unzip vim -y 修改wsl下Windows磁盘挂载点 默认的Windows磁盘在wsl的访问方式是/mnt/d/开头,d表示d盘.但是docker on linux的访问路径是 /d,所以这里需要修改挂载点路径.
sudo vim /etc/wsl.conf ##添加3行内容 [automount] root = / options = &amp;#34;metadata&amp;#34; 退出wsl重启,发现/mnt已经没了,当前目录应该是/c/xxx或者/d/xxx.
wsl安装vs code和中文字体 因为wsl没用中文字体将显示豆腐块.
# install chinese fonts for wsl,font name: &amp;#39;Noto Sans Mono CJK SC&amp;#39; sudo apt install -y fonts-noto-cjk fonts-noto-cjk-extra # Win10下载vs code的deb包,cd到该目录,使用下面命令安装 sudo apt install ./code_1.31.1-1549938243_amd64.deb # 在wsl要启动code必要依赖 sudo apt install libgtk2.0-0 libxss1 libasound2 wsl设置SSH功能 这样可以借助VcXsrv的X11转发功能打开GUI软件
&amp;gt;sudo vim /etc/ssh/sshd_config #取消Port的注释,并将端口改为2222 (端口需要大于1000) #将PasswordAuthentication的值改为yes. #重启 ssh server: sudo service ssh --full-restart #将ssh server设置为服务: sudo service ssh start windows安装VcXsrv 用它的X11转发功能.安装后默认选项即可,可以设置为开机启动.
启动wsl的vs code 在wsl输入code .,等待2秒,你会发现Windows任务栏启动了一个vs code,如果没用启动成功,说明你的VcXsrv的X11转发功能有问题.
配置vs code. 上面打开的vs code有2个问题:中文显示豆腐块,和不能全屏. 打开vs code的设置
#在字体里面先设置你想要英文字体,逗号跟上&amp;#39;Noto Sans Mono CJK SC&amp;#39; #搜索titleBarStyle,将&amp;#39;Window: title Bar Style&amp;#39;设置为 native #上面2个设置也可通过直接编辑文件设置,例如我的vs code文件设置是 &amp;gt; cat ~/.config/Code/User/settings.json { &amp;#34;Window.titleBarStyle&amp;#34;: &amp;#34;native&amp;#34;, &amp;#34;editor.fontFamily&amp;#34;: &amp;#34;monospace,&amp;#39;Noto Sans Mono CJK SC&amp;#39;&amp;#34; } 至此,已经可以在linux下面开发了.当然,其他GUI软件没用测试不确定是不是会有小问题.但是vs code已经可以应付很多开发工作了.
在wsl使用docker 目前的wsl是不支持运行docker的,但是可以在wsl使用Windows的docker,在使用上面是无感的.
 安装docker for Windows. 这个就不细说了,注意docker社区版也是需要注册才能下载的.
 启动docker for Windows,右键任务栏的docker图标,&amp;laquo;settings&amp;raquo;,勾上 &amp;laquo;expose the daemon on tcp:/localhost:2375 without TLS&amp;raquo;,这样在wsl可以访问这个docker服务.
 wsl安装docker,详细内容可以参考官方文档,下面仅列出必要bash命令.
#安装必要组件 sudo apt install -y apt-transport-https ca-certificates curl software-properties-common #gpg签名 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 #添加docker安装源 sudo add-apt-repository &amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs)\ stable&amp;#34; sudo apt update sudo apt install -y docker-ce #通过pip安装docker-compose sudo apt install -y python python-pip sudo usermod -aG docker $USER pip install --user docker-compose #验证docker安装是否成功 docker info docker-compose --version #修改docker服务为Windows的docker echo &amp;#34;export DOCKER_HOST=tcp://localhost:2375&amp;#34; &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc #验证是否可以访问Windows的docker服务,看image list命令输出和Windows的命令行下面的image list输出是不是完全一样. 可以先在Windows下用docker拉几个镜像.然后在wsl验证 docker image list 至此,wsl的docker服务也配置完成.
 </content>
    </entry>
    
     <entry>
        <title>neo4j intro</title>
        <url>https://xiongdahu.github.io/post/neo4j-intro/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>neo4j</tag><tag>code</tag><tag>database</tag>
        </tags>
        <content type="html">  neo4j图数据库介绍 neo4j是目前排名最高的图数据库,分为商业和社区版本,社区版只支持单机,而且查询的运行时(runtime)不同(cypher runtime:interpreted(社区版),slotted(企业版)). 数据库排名可以在 https://db-engines.com/en/ranking/graph&#43;dbms 查看,下一代最有前景的开源图数据库是dgraph,目前还积极开发中,生产未就绪,等他的Java客户端再成熟一点可以试用.
neo4j数据库中只有3个概念: Node, Relationship, Properties. Node表示实体类别,使用Label区分,例如一个节点可以有Person/Father等多个标签,Relationship即关系,雇佣关系,父子关系,投资关系,交易关系等. Node和Relationship都可以有Proerties,属性自身不分是属于节点还是属于关系,例如Person可以有属性name,关系也可以用属性name.你可以在neo4j browser左侧看到当前数据库的所有Node Label,Relationship Type,Properties.
本地安装和在线沙箱 neo4j背后的公司为了吸引用户,提供了一些好玩的数据库沙箱,这些沙箱数据库已经提前放了一些主题数据,例如购物数据,国会关系数据.你可以通过注册登录 https://neo4j.com/sandbox-v2/, 选择一个数据沙箱实例进行学习试玩.当然你也可以下载社区版,命令行 neo4j.bat console启动,打开127.0.0.1:7474开始学习.
一个neo4j支持多个数据库但是一次只能激活一个数据库,一个数据库所有文件都在$neo4j_home\data\databases目录的独立文件夹,在conf/neo4j.conf的dbms.active_database=graph.db指定激活那个数据库.
cypher查询语言 neo4j使用cypher语言作为查询语言.这是一种模式匹配的声明式语言.基本语法和SQL相似.
cypher中常用的子句(clause)有: MATCH,RETURN,WITH,WHERE,UNWIND,LIMIT,UNION,SKIP,SET. RETURN,LIMIT WHERE和SQL中是一样的,UNWIND这些需要用到再查看文档,这里介绍MATCH和WITH.
MTACH用于指定搜索的模式.例如希望找到&amp;rsquo;Tom Hanks&amp;rsquo;在2018演过的所有电影:MATCH (p:ACTOR {name:&#39;Tom Hanks&#39; }) -[r: ACT_IN]-&amp;gt;(m:MOVIE {time: &#39;2018&#39;}),这是一个模式,可以直接REUREN返回p,r,m等变量.可以看到模式中的节点(Node Label)使用();关系类型(Relationship Type)使用[]指定,如果不关心type,那么[]可以省略.使用&amp;ndash;; 属性(Properties) 使用{pname: pvalue}指定.
WITH的作用和python的with非常相似(实际上cypher语言借鉴了python的list处理语法),用于修改一些变量,变量一般都是上一个子句的查询结果,修改之后传给下一个子句.例如下面的语句找到和Anders有关系的人的年龄最大的那个人,返回那个人的所有认识的人的名字.
MATCH (n { name: &amp;#39;Anders&amp;#39; })--(m) WITH m ORDER BY m.age DESC LIMIT 1 MATCH (m)--(o) RETURN o.name cypher手册: https://neo4j.com/docs/cypher-manual/3.5/clauses/
cypher的操作符 如果需要进行cypher调优,有必要了解一下cypher的操作符. 一般编程语言的代码在被执行前都会被编译得到抽象语法树(AST). 例如Java代码,一个Java文件会被抽象为一个package,class, method,variable declare等不同部分得到一个Class对象. cypher语句一样会被编译得到一棵语法树(AST),每个树节点是一个操作符. 从叶节点的操作符开始执行,得到的结果依次返回给父节点进一步处理.常见的操作符有:AllNodesScan(全局扫描,只能作为叶节点),NodeByLabelScan,Apply等.例如MATCH (n) return n会得到一个AllNodesScan和ProduceResults操作符构成的AST, 你可以通过PROFILE查看你语句编译后得到的操作符构成的执行计划.
# 执行语句得到下面的表格 PROFILE MATCH (p:Person { name: &amp;#39;Tom Hanks&amp;#39; }) RETURN p # 省略了部分列 &#43;-----------------&#43;----------------&#43;------&#43;---------&#43;-----------------&#43; | Operator | Estimated Rows | Rows | DB Hits | Page Cache Hits | &#43;-----------------&#43;----------------&#43;------&#43;---------&#43;-----------------&#43; | &#43;ProduceResults | 1 | 1 | 0 | 0 | | | &#43;----------------&#43;------&#43;---------&#43;-----------------&#43; | &#43;NodeIndexSeek | 1 | 1 | 2 | 0 | &#43;-----------------&#43;----------------&#43;------&#43;---------&#43;-----------------&#43; cypher runtime pass
neo4j browser介绍 和大多数数据库一样,neo4j是server-client的数据库,支持http和bolt2中协议.neo4j自带一个基于浏览器的客户端,只需在浏览器输入serverIp:7474即可使用.
neo4j browser自带一个教程和电影关系的数据库初始化脚本.方便你可以学习.下面介绍几个常用的命令.
 :help  help命令显示各种帮助提示. 常见的topic有 :help cypher :help commands :help keys :help param
 :play 交互式学习命令. 例如,:play movie graph 进入基于电影数据库的教程.
 :param 命令,设置变量. :param usrname =&amp;gt; &amp;laquo;xiongdahu&amp;raquo;,注意,变量名和=&amp;gt;之间有空格.设置变量之后可以使用变量MATCH (n:Person) WHERE n.name = $usrname
 :params 显示当前已经设置的所有变量. 也可以使用:params {name: &amp;lsquo;Stella&amp;rsquo;, age: 24} 覆盖目前的变量. 但是这个命令没用类型安全.
  spring-neo4j配置 pass
cypher调优 cypher是一种声明式的,模式匹配的查询语言.模式在cypher语言中非常重要.如何合理地设计查询中的模式是cypher性能可调优空间最大的地方.下面给出常见的优化建议.
需要说明的是,后面的这些建议其实大都可以在cypher手册找到,如果感兴趣,建议通读这份长文档&amp;hellip;
避免全局scan cypher 是一种模式匹配的语言,默认会进行全局扫描,除非你告诉它不要.所以起始节点的label非常重要.起始的模式匹配基数大小也非常重要.
缓存和硬盘IO neo4j数据库将数据文件和Page Cache作了映射,如果在缓存中没有查询到,neo4j会从硬盘加载数据文件.第二次查询就可以走缓存.所以需要充分利用Page Cache.记住第一次查询总是会比较慢,因为没用缓存.neo4j 有2级缓存:string cache和AST cache
 string cache
默认neo4j在cache中保留1000个查询计划,可在conf/neo4j.conf中参数dbms.query_cache_size修改这个设置.
  需要注意的是cache是根据语句的string hash值判断的,所以一样的语句仅仅是大小写不一样或者空白符不一样对缓存来说也是2个语句.
PROFILE/EXPLAIN语句只会cache其去掉PROFILE/EXPLAIN之后的部分.例如:MATCH (n) return COUNT(n);和PROFILE MATCH (n) return COUNT(n);的cache是一致的.
 AST cache
编程语言都有语法树.如果在string cache中没有找到缓存.那么会将查询正规化,得到语法树并将其缓存.正规化的同时也会做一些优化,例如
match (n:Person {id:101}) return n;在正规化之后得到match (n:Person) where n.id={param1} return n; {param1: 101},AST cache不区分大小写,空格等,所以以下查询是一致的:
  match (n:Person) where n.id=101 return n; match (n:Person {id:101}) return n; MATCH ( n:Person { id : 101 } ) RETURN n; execution plan 当cypher引擎收到查询语句后如果没用找到对应的缓存,那么Cypher query planner会将语句规范化,优化后编译得到一个执行计划(execution plan).这个执行计划会缓存一切且可以复用. 当查询缓存过多,或者数据库的数据变化大时(设置参数是)这个执行计划则失效被移除.在查询中使用参数而不是字面量值,可以提高一个执行计划的复用率.
更多信息参考文档:https://neo4j.com/docs/cypher-manual/3.5/execution-plans/#execution-plan-introduction
查看查询计划 如果想要查看查询语句的执行计划,可以在查询语句前加上 EXPLANIN OR PROFILE 关键字, 你可以在neo4j browser查看query plan找到性能瓶颈.结果左侧边里面第3个tab会给出详细的性能警告(warn).
EXPLAIN只会给出语句的分析结果;而PROFILE则会执行你的查询语句把给出耗时最多的报告,以及每个操作符返回了多少行记录. 注意,profiling会消耗很多资源,所以不要在生产环境中频繁使用.调优的基础是基于cypher的操作符,所以需要你对操作符有基本的了解.
索引 数据库离不开索引.这里有个小陷阱,最早谱系的节点是企业客户(label: COR_CUSTOMER)&#43;和几十个零售客户节点(label:RTL_CUSTOMER),我在查询语句起始节点没有指定label,没用遇到性能问题,后来加入了3百万的个人节点数据后,原来1s的查询变成了1分半钟. 所以在干扰的label比较少时,你不会察觉到性能问题.务必在起始节点指定label,即使目前只有一个label,最好也提前加上.
然而,cypher语句目前不允许在一个节点指定多个label,例如你希望起点label是COR_CUSTOMER|RTL_CUSTOMER,这个是不允许的. 只能在where语句指定.
MATCH n WHERE n:COR_CUSTOMER OR n:RTL_CUSTOMER RETURN n 在3.0之前的neo4j中使用上面的语句,会导致一个AllNodesScan,在3.0之后,该语句则是将2个NodeByLabelScan匹配结果UNION然后DISTINCT的结果. 所以是搜索2次再合并结果.你可以在上面的cypher语句前面添加EXPLAIN查看执行计划,已确定你的语句是否会导致全局扫描.
SO上关于多个label匹配的讨论
大结果集 如果你的查询返回结果集太大,例如几M大小,那么你可能需要考虑你的设计了. 过大的结果集会导致查询返回变慢,要注意,这些结果会占用你的缓存空间,而如果在网络情况不好时,情况家更加糟糕了.
目前谱系对这一块并没有优化,最大的谱系的返回接口可能达到1M多,加上ES的数据,前端接收数据会有4M多.
锁 当你修改节点的信息时,节点会被锁定;如果修改关系,关系会被锁定;如果增加/删除关系,那么2个节点和这个关系都会被锁定.而如果此时有节点/关系的相关查询请求,这些请求会等待.所以,如果你需要将50个节点加入一个组(group)&amp;ndash;即添加50个关系,如果你调用50次方法,那么这个group节点被lock的时间较长,此时可以通过UNWIND和列表(list)参数处理这个问题.
MATCH (g:Group { uuid: $groupUuid }) UNWIND $personUuidList as personUuid MATCH (p:Person { uuid : personUuid }) MERGE (p)-[:IS_MEMBER]-&amp;gt;(g)  常见查询错误  变量名
 label忘记添加冒号,例如MATCH (Person) 和 MATCH (:Person) 是完全不一样的,前者Person是变量,不走索引.
 有过大的中间结果集,优化你的语句时思考:尽早distinct,尽早limit,使用collect减少结果的行数,在正确地方使用order by;
  多个UNWIND语句导致笛卡尔积 多个UNWIND会导致一个笛卡尔积的结果,这个结果可能会很大.例如下面的结果会得到3*3=9行,所以尽量避免笛卡尔积.
with [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;] as lts, [1,2,3] as nrs unwind lts as char unwind nrs as nr return char,nr 在MATCH中使用多个模式笛卡尔积 在MATCH中使用多个模式也会导致笛卡尔积,比较下面的2个结果相同的语句,第一个耗时80s,第二个只需8ms.
# 1. 笛卡尔积 80000 ms w/ ~900 players, ~40 teams, ~1200 games MATCH (pl:Player),(t:Team),(g:Game) RETURN COUNT(DISTINCT pl), COUNT(DISTINCT t), COUNT(DISTINCT g) # 2. 8ms w/~900 players, ~40 teams, ~1200 games MATCH (pl:Player) WITH COUNT(pl) as players MATCH (t:Team) WITH COUNT(t) as teams, players MATCH (g:Game) RETURN COUNT(g) as games, teams, players 模式中的方向 下面的查询中,如果给关系ACTED_IN添加上方向,可以提高查询速度.
MATCH (p:Person)-[:ACTED_IN]-(m) WHERE p.name = &amp;#34;Tom Hanks&amp;#34; RETURN m</content>
    </entry>
    
     <entry>
        <title>Spark Basic</title>
        <url>https://xiongdahu.github.io/post/spark-basic/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>code</tag><tag>spark</tag>
        </tags>
        <content type="html">  引言 大数据计算和普通的程序并无本质区别：数据输入=&amp;gt;计算=&amp;gt;输出和结果的持久化。这里的挑战在于计算的效率和容错性。由于数据输入巨大，计算的效率是基本的要求。为了在通用硬件上高效完成大量计算，唯一的途径就是将计算任务拆分分布式计算。这就引出了新的问题：分布式计算资源的管理（Mesos，YARN），分布式计算失败后的恢复（容错性）（Spark RDD），以及分布式的数据输入和保存（分布式文件HDFS）。hadoop生态圈就是为了解决几个问题设计的(YARN,MapR,HDFS)。只不过在计算这一环节Spark做的更加高效取代了MapR。所以先看下hadoop的核心两个组件。
HDFS  HDFS是hadoop的虚拟分布式文件系统。满足大数据问题下要求的：可扩展的，容错的，硬件通用的和高并发的特性。HDFS最重要的特性是不可变性&amp;ndash;数据提交到HDFS后即不可更新了，也就是所谓的WORM(write once read many)。
 文件在HDFS中是以block构成，默认一个block是128M。block是是分布式的，即如果集群中如果有多于1个节点，那么有文件可能会被分布在多个节点上。block是被复制的，这主要是两个目的：1.容错，2.增加数据局部性的概率，有利于访问。block复制在数据节点接收（ingest：消化）block时同时发生。如图所示：
   NameNode：不知道怎么翻译，NameNode主要负责管理HDFS的元数据，包括directory,文件对象和相关属性（e.g. ACL)，元数据是常驻内存中的，硬盘上也有备份以及日志保证持久性和崩溃后的一致性（和数据库相似）。还包括block的位置信息&amp;ndash;block之间的关系。注意，数据（文件）并不经过NameNode，否则很容易成为性能瓶颈，数据是直接到达DataNode，并上报给NameNode管理。
 数据节点（DataNode）负责：block复制；管理本节点的存储；向NameNode上报block信息。注意，数据节点不会意识到HDFS的目录（directory）和文件（Files）的概念，这些信息是NameNode管理保存的，客户端只会和NameNode交道。
 hdfs客户端分为：fs shell;hdfs java api;rest proxy接口（HttpFS等）。
 常见命令：
  # 上传一个文件 -f表示覆盖 hadoop fs -put -f jour.txt /user/dahu/jour/ # 下载 hadoop fs -get /user/dahu/jour/jour.txt # ls hadoop fs -ls /user/dahu/ # 删除 -r表示递归，删除目录 hadoop fs -rm /user/dahu/jour/jour.txt hadoop fs -rm -r /user/dahu/jour YARN  YARN:Yet Another Resource Negotiator是hadoop的资源管理器。YARN有个守护进程&amp;ndash;ResourceManager,负责全局的资源管理和任务调度，把整个集群当作计算资源池，只关注分配，不管应用，且不负责容错。YARN将application（或者叫job）分发给各个NodeManager,NodeManager是实际的worker或者worker的代理。ResourceManager主要有两个组件：Scheduler 和 ApplicationsManager。 下图是YARN的结构示意图：
   上图中ResourceManager负责管理和分配全局的计算资源。而NodeManager看着更复杂一些：1.用户提交一个app给RM（ResourceManager）；2.RM在资源充足的NodeManager上启动一个ApplicationMaster（也就是这个app对应的第一个container）。3.ApplicationMaster负责在所有NodeManagers中协调创建几个task container，也包括ApplicationMaster自己所在的NodeManager（上图中紫色2个和红色的4个分别表示2个app的task container和ApplicationMaster）。4. NodeManager向各个ApplicationMaster汇报task container的进展和状态。5. ApplicationMaster向RM汇报应用的进展和状态。6.RM向用户返回app的进度，状态，结果。用户一般可通过Web UI查看这些。
 上面的示意图是YARN 的核心概念，Spark程序的运行结构示意图和上面的示意图相同。每个组件都可以近似一样的理解，例如，上面的Client在Spark中叫Driver程序;ResourceManager在Spark中叫Cluster Manager（为了理解方便，认为一样即可，Spark的ClusterManager目前主要有YARN,Mesos和Spark自带的三种）；NodeManager就是Spark中的Worker Node。
  Spark基本概念  上图中的client程序在Spark中即Driver程序。Driver就是我们编写Spark程序app的主要部分，包括SparkContext的创建和关闭以及计算任务（Task）的计划（Planning,包括数据数据，转换，输出，持久化等)。SparkContext负责和Cluster Manager通信，进行资源申请，任务的分配和监控。一般认为SparkContext代表Driver。
 ClusterManager：就是上面说的三种-Standalone,YARN,Mesos。
 ＷorkerNode: 集群中运行app代码的节点，也就是上图中YARN的NodeManager节点。一个节点运行一个/多个executor.
 Executor：app运行在worker节点的一个进程，进程负责执行task的planning。Spark On YARN 中这个进程叫CoarseGrainedExecutorBackend。每个进程能并行执行的task数量取决于分配给它的CPU个数了。下图是一个Spark程序集群概览图，和上图很相似。
   仔细对比上面两个示意图，在YARN的结构示意图中,ResourceManager为程序在某个NodeManager上创建的第一个container叫ApplicationMaster，ApplicationMaster负责只是其他的task container。在Spark On YARN有两种运行模式：client和cluster模式。在cluster模式下，用户编写的driver程序运行在YARN的ApplicationMaster的内部。
*RDD:Spark的核心数据结构。后面详细介绍，可以简单的理解为一个Spark程序所有需要处理的数据在Spark中被抽象成一个RDD，数据需要被拆分分发到各个worker去计算，所以RDD有一个分区（Partation）概念。一般我们的数据是放在分布式文件系统上的(e.g. HDFS)，可以简单理解为一个RDD包含一或多个Partation，每个Partation对应的就是HDFS的一个block。当然，Partation不是和HDFS的block绑定的，你也可以手动的对数据进行分区，即使他们只是待处理的一个本地文件或者一个小数组。 一个Partation包含一到多个Record，Record可以理解为文本中的一行，excel的一条记录或者是kafka的一条消息。
 Task：RDD的一个Patation对应一个Task,Task是单个分区上最小的处理单元。
  RDD pass
SparkStreaming pass
SparkStreaming&#43;Kafka import org.apache.kafka.clients.consumer.ConsumerRecord import org.apache.kafka.common.serialization.StringDeserializer import org.apache.spark.streaming.kafka010._ import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe val kafkaParams = Map[String, Object]( &amp;#34;bootstrap.servers&amp;#34; -&amp;gt; &amp;#34;localhost:9092,anotherhost:9092&amp;#34;, &amp;#34;key.deserializer&amp;#34; -&amp;gt; classOf[StringDeserializer], &amp;#34;value.deserializer&amp;#34; -&amp;gt; classOf[StringDeserializer], &amp;#34;group.id&amp;#34; -&amp;gt; &amp;#34;use_a_separate_group_id_for_each_stream&amp;#34;, &amp;#34;auto.offset.reset&amp;#34; -&amp;gt; &amp;#34;latest&amp;#34;, &amp;#34;enable.auto.commit&amp;#34; -&amp;gt; (false: java.lang.Boolean) ) val topics = Array(&amp;#34;topicA&amp;#34;, &amp;#34;topicB&amp;#34;) val stream = KafkaUtils.createDirectStream[String, String]( streamingContext, PreferConsistent, Subscribe[String, String](topics, kafkaParams) ) stream.map(record =&amp;gt; (record.key, record.value)) DStream的elements:record is ConsumerRecord: A key/value pair to be received from Kafka. This consists of a topic name and a partition number, from which the record is being received and an offset that points to the record in a Kafka partition.包含key(),offset(),partation()方法等。
 当一个StreamingContext中有多个input stream时，记得保证给程序分配了足够的资源（特别是core的数量，必须大于输入源的数量）。
 本地执行程序时，不要使用“local” or “local[1]” as the master URL，streaming程序至少需要两个thread，一个接受数据，一个处理数据。直接使用local[n],n&amp;gt;输入源个数。
 DStream 和RDD一样支持各种trans和action
 DStream is batches of RDDs.
  常见错误 dstream.foreachRDD { rdd =&amp;gt; val connection = createNewConnection() // executed at the driver  rdd.foreach { record =&amp;gt; connection.send(record) // executed at the worker  } } // 上面的写法会导致connection 不可序列化的错误。因为connection需要被发送到worker上，所以必须可以序列化； // 但是这样的连接对象其实非常少的（第三方库一般都不支持）； dstream.foreachRDD { rdd =&amp;gt; rdd.foreach { record =&amp;gt; val connection = createNewConnection() connection.send(record) connection.close() } } // 上面是给每个record处理时新建一个连接，会导致严重的性能问题。 // 更好的方式是给每个partation新建一个连接  dstream.foreachRDD { rdd =&amp;gt; rdd.foreachPartition { partitionOfRecords =&amp;gt; val connection = createNewConnection() partitionOfRecords.foreach(record =&amp;gt; connection.send(record)) connection.close() } } // 最好的方法是维护一个静态线程池： dstream.foreachRDD { rdd =&amp;gt; rdd.foreachPartition { partitionOfRecords =&amp;gt; // ConnectionPool is a static, lazily initialized pool of connections  val connection = ConnectionPool.getConnection() partitionOfRecords.foreach(record =&amp;gt; connection.send(record)) ConnectionPool.returnConnection(connection) // return to the pool for future reuse  } } Note that the connections in the pool should be lazily created on demand and timed out if not used for a while. This achieves the most efficient sending of data to external systems.  DStream的RDD分区数是由topic分区数相同的。
  最佳实践 </content>
    </entry>
    
     <entry>
        <title>java generic</title>
        <url>https://xiongdahu.github.io/post/java-generic/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  泛型 // 类 class Tuple&amp;lt;T, S&amp;gt; { private T first; private S second; } // 泛型方法也可在非泛型类里面 class ArrayAlg { public static &amp;lt;T&amp;gt; T getMiddle(T... a) { return a[a.length / 2]; } }String middle = ArrayAlg.&amp;lt;String&amp;gt;getMiddle(&amp;#34;]ohnM, &amp;#34;Q.n, &amp;#34;Public&amp;#34;);// right,&amp;lt;String&amp;gt;可以省略  String middle = GenericCls.getMiddle(&amp;#34;hello&amp;#34;,0,null);// error  // Errr:(7, 45) java: 不兼容的类型: 推断类型不符合上限 // 推断: java.lang.Object&amp;amp;java.io.Serializable&amp;amp;java.lang.Comparable&amp;lt;? extends java.lang.Object&amp;amp;java.io.Serializable&amp;amp;java.lang.Comparable&amp;lt;?&amp;gt;&amp;gt; // 上限: java.lang.String,java.lang.Object  类型限定 public static &amp;lt;T extends Comparable&amp;gt; T min(T a) // 如果多个类型，则：T extends Comparable &amp;amp; Serializable // 只能有一个类，且类必须紧跟extends，但是可以有多个接口 类型擦除 //Tuple&amp;lt;T,S&amp;gt;在虚拟机变为 class Tuple { private Object first;//当调用getFirst时,则发生强制转换  private Object second; } //泛型方法同样有擦除 public static &amp;lt;T extends Comparable&amp;gt; T min(T a) // =&amp;gt; public static Comparable min(Comparable a) 约束  不能用基本类型实例化泛型,Pair&amp;lt;double&amp;gt;不允许
 运行时参数类型检查只能检查原始类型
  if (a instanceof Pair&amp;lt;String&amp;gt;) // Error if (a instanceof Pair&amp;lt;T&amp;gt;) // Error Pair&amp;lt;String&amp;gt; p = (Pair&amp;lt;String&amp;gt;) a; //warning  不能创建参数化类型的数组
  Pair&amp;lt;String&amp;gt;[] table = new Pair&amp;lt;String&amp;gt;[10]; // Error Pair&amp;lt;String&amp;gt;[] table; //声明是合法的,只是无法实例化  借助@SafeVarargs参数化类型的数组
@SafeVarargs public static &amp;lt;T&amp;gt; void addAll(Collection&amp;lt;T&amp;gt; coll, T... ts)  Class类本身是泛型。 例如，String.daSS 是一个 Class 的实例（事实上，它是唯一的实例。) 因此，makePair 方法能够推断出 pair 的类型
 泛型类的静态上下文中类型变量无效
  public class Singleton&amp;lt;T&amp;gt; { private static T singlelnstance; // Error public static T getSinglelnstance{// Error  if (singleinstance == null) {//construct new instance of T  return singlelnstance; } } } 不能抛出或捕获泛型类的实例
  public class Problem&amp;lt;T&amp;gt; extends Exception { /* . . . */ } // Error can&amp;#39;t extend Throwable  泛型擦除的方法冲突
  public class Pair&amp;lt;T&amp;gt; { T first; T second; public boolean equals(T value) { //error 和Object.equals冲突  return first.equals(value) &amp;amp;&amp;amp; second, equals(value); } } 泛型继承 class Employee class Manager extends Employee //Pair&amp;lt;Employee&amp;gt; 和Pair&amp;lt;Manager&amp;gt; 没用任何继承关系 通配符 和 PECS Pair&amp;lt;? extends Employee〉 Pair&amp;lt;? super Manager 反射和泛型 </content>
    </entry>
    
     <entry>
        <title>IO-Java-Stream-Write-Reader</title>
        <url>https://xiongdahu.github.io/post/io-java-stream-write-reader/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  java reader writer stream 上次总结了java 678 中不同读写文件的方法，这次总结一下基本的IO流。网上的总结大部分是以Stream和Reader、Writer来介绍的。这次从封装层次来介绍。
首先是byte流，每次read()读取8 bits，并用一个int的低八位保存：
FileInputStream in = null; FileOutputStream out = null; try { in = new FileInputStream(&amp;#34;xanadu.txt&amp;#34;); out = new FileOutputStream(&amp;#34;outagain.txt&amp;#34;); int c; while ((c = in.read()) != -1) { out.write(c); } } finally { if (in != null) { in.close(); } if (out != null) { out.close(); } } byte流是很基础的流，接下来是字符流，使用int的低16位保存读取内容，一个汉字，使用上面那个字节流，需要读取2次，使用下面的字符流，只用一次。其实背后还是一个桥接
具体的对象体现：
FileReader extemds InputStreamReader,
FileWriter extends OutputStreamWriter
InputStreamReader:字节到字符的桥梁
OutputStreamWriter:字符到字节的桥梁：
FileReader inputStream = null; FileWriter outputStream = null; try { inputStream = new FileReader(&amp;#34;xanadu.txt&amp;#34;); outputStream = new FileWriter(&amp;#34;characteroutput.txt&amp;#34;); int c; while ((c = inputStream.read()) != -1) { outputStream.write(c); } } finally { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } } ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。StringBufferInputStream 已经被Deprecated，设计错误，只是为了兼容。
File I/O现在已经不推荐使用了，推荐nio2的Path及其工具类Files,Paths;
Path 官方教程
ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）
注意：OutputStream子类中没有StringBuffer为目的地的。ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。
几个特殊的类：
PushbackInputStream 的功能是查看最后一个字节，不满意就放入缓冲区。主要用在编译器的语法、词法分析部分。输出部分的BufferedOutputStream 几乎实现相近的功能。
PrintStream 也可以认为是一个辅助工具。主要可以向其他输出流，或者FileInputStream 写入数据，本身内部实现还是带缓冲的。本质上是对其它流的综合运用的一个工具而已。一样可以踢出IO 包！System.out 和System.err 就是PrintStream 的实例！ System.in是inputStream的实例！
你永远不应该new PrintStream,请用PrintWriter
看看字符流的对比：
CharReader、StringReader 是两种基本的介质流，它们分别将Char 数组、String中读取数据。PipedReader 是从与其它线程共用的管道中读取数据。
BufferedReader 很明显就是一个装饰器，它和其子类负责装饰其它Reader 对象。
FilterReader 是所有自定义具体装饰流的父类，其子类PushbackReader 对Reader 对象进行装饰，会增加一个行号。
InputStreamReader 是一个连接字节流和字符流的桥梁，它将字节流转变为字符流。FileReader 可以说是一个达到此功能、常用的工具类，在其源代码中明显使用了将FileInputStream 转变为Reader 的方法。我们可以从这个类中得到一定的技巧。Reader 中各个类的用途和使用方法基本和InputStream 中的类使用一致。后面会有Reader 与InputStream 的对应关系。
OutputStreamWriter 是OutputStream 到Writer 转换的桥梁，它的子类FileWriter 其实就是一个实现此功能的具体类（具体可以研究一SourceCode）。功能和使用和OutputStream 极其类似，后面会有它们的对应图。
PrintWriter 和PrintStream 极其类似，功能和使用也非常相似。但是还是有不同的，PrintStream prints to an OutputStream, and PrintWriter prints to a Writer.
你永远不应该new PrintStream,请用PrintWriter
PrintStream stream = new PrintStream(outputStream); //With the PrintWriter you can however pass an OutputStreamWriter with a specific encoding. PrintWriter writer = new PrintWriter(new OutputStreamWriter(outputStream, &amp;#34;UTF-8&amp;#34;)); Piped流 这是线程之间通信使用的。后面介绍。
RandomAccessFile类 该对象并不是流体系中的一员，其封装了字节流，同时还封装了一个缓冲区（字符数组），通过内部的指针来操作字符数组中的数据。 该对象特点：
该对象只能操作文件，所以构造函数接收两种类型的参数：a.字符串文件路径；b.File对象。
该对象既可以对文件进行读操作，也能进行写操作，在进行对象实例化时可指定操作模式(r,rw)
注意：该对象在实例化时，如果要操作的文件不存在，会自动创建；如果文件存在，写数据未指定位置，会从头开始写，即覆盖原有的内容。 可以用于多线程下载或多个线程同时写数据到文件。
Scanning and formatting The scanner API breaks input into individual tokens associated with bits of data,The formatting API assembles data into nicely formatted, human-readable form.
formatting
int i = 2; double r = Math.sqrt(i); System.out.format(&amp;#34;The square root of %d is %f.%n&amp;#34;, i, r);Scanner s = new Scanner(new BufferedReader(new FileReader(&amp;#34;xanadu.txt&amp;#34;))); By default, a scanner uses white space to separate tokens. also,u can set :
s.useDelimiter(&amp;quot;,\\s*&amp;quot;);
I/O from commandline You might expect the Standard Streams to be character streams, but, for historical reasons, they are byte streams. System.out and System.err are defined as PrintStream objects. Although it is technically a byte stream, PrintStream utilizes an internal character stream object to emulate many of the features of character streams.
By contrast, System.in is a byte stream with no character stream features. To use Standard Input as a character stream, wrap System.in in InputStreamReader.
InputStreamReader cin = new InputStreamReader(System.in);
！！！！妈的，老子开始就困惑很久了，一直不明白System.out怎么可以直接打印出中文。
jdk1.5开始读写控制台以前常用的是Scanner：
Scanner scanner = new Scanner(System.in); scanner.nextLine();  从 JDK1.6开始，基本类库中增加了java.io.Console 类，用于获得与当前 Java 虚拟机关联的基于字符的控制台设备。在纯字符的控制台界面下，可以更加方便地读取数据。
Console console = System.console(); if (console == null) { throw new IllegalStateException(&amp;#34;不能使用控制台&amp;#34;); } return console.readLine(prompt);  Data Streams Data streams support binary I/O of primitive data type values (boolean, char, byte, short, int, long, float, and double) as well as String values. All data streams implement either the DataInput interface or the DataOutput interface. This section focuses on the most widely-used implementations of these interfaces, DataInputStream and DataOutputStream.
致谢：Oubo的博客
</content>
    </entry>
    
     <entry>
        <title>Java-6-7-8-文件读写</title>
        <url>https://xiongdahu.github.io/post/io-java-6-7-8-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html"> *[] 重要的类
*[] 文件读写场景
资料：Reading and writing text files
不要用File对象，改用Path对象，该对象既表示文件路径，也表示文件文本（应该认为文件也是路径的一部分），对于以前的File,可以File.toPath()得到一个Path对象。
Files是一个静态类，操作文件内容。Paths是静态工具类，操作文件路径，例如拼接文件路径，以前要使用平台无关的分隔符表示：File.pathSeparator， File.separator
现在可以直接使用下面方法
Path path = Paths.get(&amp;quot;~/test/&amp;quot;, &amp;quot;foo&amp;quot;, &amp;quot;bar&amp;quot;, &amp;quot;a.txt&amp;quot;);
下面一段代码很好的显示了在java678中的读取文件方法：
package angus.java.interview; import java.io.BufferedReader; import java.io.FileInputStream; import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.nio.charset.StandardCharsets; import java.nio.file.Files; import java.nio.file.Paths; public class FileToStringJava678 { public static void main(String[] args) throws IOException { // How to read file into String before Java 7 	InputStream is = new FileInputStream(&amp;#34;filetoStringjava678.txt&amp;#34;); BufferedReader buf = new BufferedReader(new InputStreamReader(is)); String line = buf.readLine(); StringBuilder sb = new StringBuilder(); while (line != null) { sb.append(line).append(&amp;#34;\n&amp;#34;); line = buf.readLine(); } String fileAsString = sb.toString(); System.out.println(&amp;#34;Contents (before Java 7) : &amp;#34; &#43; fileAsString); // Reading file into Stirng in one line in JDK 7 	String contents = new String(Files.readAllBytes(Paths.get(&amp;#34;filetoStringjava678.txt&amp;#34;))); System.out.println(&amp;#34;Contents (Java 7) : &amp;#34; &#43; contents); // Reading file into String using proper character encoding 	String fileString = new String(Files.readAllBytes(Paths.get(&amp;#34;filetoStringjava678.txt&amp;#34;)), StandardCharsets.UTF_8); System.out.println(&amp;#34;Contents (Java 7 with character encoding ) : &amp;#34; &#43; fileString); // It&amp;#39;s even easier in Java 8 	Files.lines(Paths.get(&amp;#34;filetoStringjava678.txt&amp;#34;), StandardCharsets.UTF_8).forEach(System.out::println); } } 下面是更新版本，几乎所有文件操作都有了
// 记住，bytes 到string 永远指定字符集，即使目前只是英文文件。 // ### java 8按行读取：  public class Main { public static void main(String[] args) { String fileName = &amp;#34;c://lines.txt&amp;#34;; try (Stream&amp;lt;String&amp;gt; stream = Files.lines(Paths.get(fileName))) { stream.forEach(System.out::println);//or other thing you do with stream  } catch (IOException e) { e.printStackTrace(); } } } // ### java 7：  BufferedReader br = new BufferedReader(new FileReader(file)); String line; while((line = br.readLine()) != null) { // do something with line.  } // 输入流保存到文件： Files.copy(inputStream,filepath,StandardCopyOption.REPLACE_EXISTING); public class Java7IO { public static void main(String[] args) throws IOException { //读取所有字节：  Path path = Paths.get(&amp;#34;alice.txt&amp;#34;); String content = new String(Files.readAllBytes(path), StandardCharsets.UTF_8); System.out.println(&amp;#34;Characters: &amp;#34; &#43; content.length()); //读取所有行：  List&amp;lt;String&amp;gt; lines = Files.readAllLines(path, StandardCharsets.UTF_8); System.out.println(&amp;#34;Lines: &amp;#34; &#43; lines.size()); //JAVA 8 延迟处理：  try (Stream&amp;lt;String&amp;gt; lineStream = Files.lines(path, StandardCharsets.UTF_8)) { System.out.println(&amp;#34;Average line length: &amp;#34; &#43; lineStream.mapToInt(String::length).average().orElse(0)); } //按单词读取：  try (Scanner in = new Scanner(path, &amp;#34;UTF-8&amp;#34;)) { in.useDelimiter(&amp;#34;\\PL&#43;&amp;#34;);//？  int words = 0; while (in.hasNext()) { in.next(); words&#43;&#43;; } System.out.println(&amp;#34;Words: &amp;#34; &#43; words); } //读取一个网页：  URL url = new URL(&amp;#34;http://horstmann.com/index.html&amp;#34;); try (BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream()))) { Stream&amp;lt;String&amp;gt; lineStream = reader.lines();////!!!! BufferedReader TO Stream  System.out.println(&amp;#34;Average line length: &amp;#34; &#43; lineStream.mapToInt(String::length).average().orElse(0)); } //PrintWriter 向文本写文件：  path = Paths.get(&amp;#34;hello.txt&amp;#34;); try (PrintWriter out = new PrintWriter(Files.newBufferedWriter(path, StandardCharsets.UTF_8))) { out.println(&amp;#34;Hello&amp;#34;); } //Files.write向文本写文件：  content = &amp;#34;World\n&amp;#34;; Files.write(path, content.getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND); //多行写入  String fileName = &amp;#34;file.txt&amp;#34;; Path path = Paths.get(&amp;#34;file1.txt&amp;#34;); List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); try (Stream&amp;lt;String&amp;gt; lines = Files.lines(Paths.get(fileName))) { lines.forEach(list::add); Files.write(path, list, StandardCharsets.UTF_8); } catch (IOException e) { e.printStackTrace(); } //打印错误栈：  StringWriter writer = new StringWriter(); Throwable throwable = new IllegalStateException(); throwable.printStackTrace(new PrintWriter(writer)); String stackTrace = writer.toString(); System.out.println(&amp;#34;Stack trace: &amp;#34; &#43; stackTrace); } } // 直接将url中的pdf保存下来：//适用于任何二进制文件：URL url = new URL(&amp;#34;http://www.cninfo.com.cn/1202417936.PDF&amp;#34;); try (InputStream in = new BufferedInputStream(url.openStream())) { Files.copy(in, Paths.get(url.getFile().substring(1)),StandardCopyOption.REPLACE_EXISTING); }//url.getFile().substring(1)去掉起始地斜杠符 //copy()有三种形式 	//还有一种方式jdk7之前： URL website = new URL(&amp;#34;XXX.pdf&amp;#34;); ReadableByteChannel rbc = Channels.newChannel(website.openStream()); FileOutputStream fos = new FileOutputStream(url.getFile().substring(1)); fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE); //FileChannel的抽象方法abstract long	transferFrom(ReadableByteChannel src, long position, long count) </content>
    </entry>
    
     <entry>
        <title>Java concurrency 1 basic</title>
        <url>https://xiongdahu.github.io/post/java-concurrency-1-basic/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  知识点太多了。先列举一些知识点，然后在分别做一点笔记。
模式 1。 共享可变性
2。 隔离可变性
3。 纯粹不可变性:STM,
IO密集型任务和计算密集型任务 读写文件和网络请求这种算IO密集型任务，阻塞时间长，任务阻塞系数接近1；线程池大一点好，
判断质数的这种任务属于计算密集型任务，阻塞系数约为0。
poolSize = cores/(1-blockingCofficient); cores 是处理器核心数。
场景：
根据网络服务api计算给定股票代码和股票数的资产总值。-IO密集
判断n以内的所有素数。 &amp;ndash; 计算密集
Java5以前的一些同步方法api 尽量不要使用，但是要理解。wait/notify、join等函数，synchronized volatile关键字的理解。笔记
 用ExecutorService代替Thread及其方法。笔记
 用Lock和子类的方法代替synchronized。但是不绝对。 笔记
 以前用wait/notify的地方，现在可以用CyclicBaerrier和CountDownLatch同步工具代替。笔记
  同步容器和并发容器 同步容器包括Vector和Hashtable(java.util.Properties 也是一个HashTable)，使用synchronized同步。不建议使用，但是要知道HashTable和HashMap区别：
Java 中 HashMap 和 HashTable 有几个不同点：
 Hashtable 是同步的，然而 HashMap 不是。 这使得HashMap更适合非多线程应用，因为非同步对象通常执行效率优于同步对象。
 Hashtable 不允许 null 值和键。HashMap允许有一个 null 键和一个 NULL 值。
 HashMap的一个子类是LinkedHashMap。所以，如果想预知迭代顺序（默认的插入顺序），只需将HashMap转换成一个LinkedHashMap。用Hashtable就不会这么简单。
 如果同步对你来说不是个问题，我推荐使用HashMap。如果同步成为问题，你可能还要看看ConcurrentHashMap。
  迭代hashmap最佳方式：
Iterator it = mp.entrySet().iterator(); while (it.hasNext()) { Map.Entry pair = (Map.Entry)it.next(); System.out.println(pair.getKey() &#43; &amp;#34; = &amp;#34; &#43; pair.getValue()); it.remove(); // avoids a ConcurrentModificationException } 并发容器是和java.util.concurrent包一块发布的。包括很多新的并发容器：
并发容器架构图
图中最底部的都是jdk1.5增加的并发容器：主要有：ConcurrentHashMap,CopyOnWriteList, BlockingQueue等。
参考书籍： Doug Lea 《Concurrent Programming in Java》 2004
Brian Goetz 《java concurrency in practice》 2007
Venkat 《Programming concurrency on the JVM》
</content>
    </entry>
    
     <entry>
        <title>Java concurrency 2 Runnable Callable FutureExecutor</title>
        <url>https://xiongdahu.github.io/post/java-concurrency-2-runnable-callable-future-executor/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  定义任务的内容 多线程编程的核心元素就是任务，任务是独立的活动。不依赖其他任务的状态，结果，以及边界效应。
定义任务的内容使用Runnable和Callable。
Runnable 接口表示没有返回的一个过程（procedure），没有受检异常。
Callabe 接口的call方法会返回一个结果，并有可能抛出受检异常。如果要表示没有返回值，可以使用Callable&amp;lt;Void&amp;gt;,但是不鼓励使用这个代替Runable，但一个任务内容没有返回值，只是利用副作用时，应该优先使用Runable，使得含义清晰，并且JDK中ScheduledExecutorService也有只能接收Runable的方法。
可以将Runnable定义的任务提交给Thread直接运行，但是这个线程是不可重用的。更好的方法是提交给执行器ExecutorService。
Future接口描述了任务的生命周期，并提供方法获得任务执行的结果。该接口有一个实现类：FutureTask。该类的实例一定和一个具体任务相关。ExecutorService所有的submit方法都会返回一个Future实例。你也可以直接通过FutureTask构造函数将Runnable/Callable构建一个FutureTask实例。该实例将管理该任务的生命周期
注意，FutureTask 实现了Runnable和Future（通过实现RunnableFuture 接口，如下），所以既可以使用ExecutorService，也可以使用Thread执行任务内容。
public class FutureTask&amp;lt;V&amp;gt; implements RunnableFuture&amp;lt;V&amp;gt; public interface RunnableFuture&amp;lt;V&amp;gt; extends Runnable, Future&amp;lt;V&amp;gt; Future.get是一个阻塞方法，如果任务没有结束或者没有抛出异常，那么会一直等待下去，如果需要异步的使用ComletionService。
ExecutorService 执行器框架，root 接口是Executor，只有一个execute方法执行runnable实例。更常用是子接口ExecutorService，除了可以执行runnable，callable，还可以invoke一callable集合：
&amp;lt;T&amp;gt; List&amp;lt;Future&amp;lt;T&amp;gt;&amp;gt;	invokeAll(Collection&amp;lt;? extends Callable&amp;lt;T&amp;gt;&amp;gt; tasks) &amp;lt;T&amp;gt; T	invokeAny(Collection&amp;lt;? extends Callable&amp;lt;T&amp;gt;&amp;gt; tasks) &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt;	submit(Callable&amp;lt;T&amp;gt; task) Future&amp;lt;?&amp;gt;	submit(Runnable task) ScheduledExecutorService The ScheduledExecutorService interface supplements the methods of its parent ExecutorService with schedule, which executes a Runnable or Callable task after a specified delay. In addition, the interface defines scheduleAtFixedRate and scheduleWithFixedDelay, which executes specified tasks repeatedly, at defined intervals.
scheduleAtFixedRate: 第一次是initialDelay 后执行，第二次是initialDelay &#43; 1 * period 后执行，类推。
scheduleWithFixedDelay: 是前面任务执行结束后开始计算间隔计时。
两个方法都不会并发执行任务，特别是第一个方法，如果任务时间比参数中等待时间period长，那么只会延期执行。对于第二个方法，本来就是要等前面结束才执行，所以没有这个问题。两个方法遇到异常，那么后面任务也不会执行，因为任务是重复的，后面也会遇到异常。周期任务可以取消，或者遇到执行器终结才结束。
CompletionService 如果有多个任务，那么ExecutorService只能不停的轮询Future看是否有任务结束，并取得结果。CompletionService则是另外是自动的告诉你那些任务结果已经准备好。注意构造方法需要一个ExecutorService
 ExecutorService = incoming queue &#43; worker threads
CompletionService = incoming queue &#43; worker threads &#43; output queue 参考
ExecutorService executor = Executors.newFixedThreadPool(numberOfThreadsInThePool); CompletionService&amp;lt;String&amp;gt; completionService = new ExecutorCompletionService&amp;lt;String&amp;gt;(executor); for (final String num: nums) { completionService.submit(new Task(num)); //Task is Callable  } try { for (int t = 0, n = nums.size(); t &amp;lt; n; t&#43;&#43;) { Future&amp;lt;String&amp;gt; f = completionService.take(); System.out.print(f.get()); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } catch (ExecutionException e) { Thread.currentThread().interrupt(); } finally { if (executor != null) { executor.shutdownNow(); } }</content>
    </entry>
    
     <entry>
        <title>Java concurrency 3 synchronized or Lock</title>
        <url>https://xiongdahu.github.io/post/java-concurrency-3-synchronized-or-lock/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  synchronized method和synchronized block的区别 如果是synchronized(this),那么和synchronized 方法没有任何区别，锁定对象都是方法所在的对象。
synchronized void mymethod() { ... } void mymethod() { synchronized (this) { ... } } 但是synchronized block可以锁定其他对象，而且synchronized block的范围是可以控制更灵活，synchronized 方法的边界只能是整个方法
private void method() { // code here  // code here  // code here  synchronized( lock ) { // very few lines of code here  } // code here  // code here  // code here } 不要忘记synchronized 这个指令是JVM内置的，也是未来可以优化的。如果只是简单的同步一个资源对象，就使用synchronized，而且，使用Lock有就必须出现一堆的try/finally。
使用ReentrantLock场景：
需要以下高级特性时 ： 可定时的，可轮询的，可中断的锁，公平队列，非块结构。
stackoverflow回答
</content>
    </entry>
    
     <entry>
        <title>Java concurrency 4 CAS and atomic</title>
        <url>https://xiongdahu.github.io/post/java-concurrency-4-cas-and-atomic/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  AtomicLong code: public final long incrementAndGet() { for (;;) { long current = get(); long next = current &#43; 1; if (compareAndSet(current, next)) return next; } } //in java 8: public final long incrementAndGet() { return unsafe.getAndAddLong(this, valueOffset, 1L) &#43; 1L; } 基础 第一个版本是基于cas的，cas基于一个基础：有三个值，新值N，预期内存中的值E，内存中需要更新的值V，如果V == E,那么将V设置为N,返回V，结束；如果V != E，说明有别的线程动了这个v,那么不做修改直接返回V。cas在X86下对应的是 CMPXCHG 汇编指令
java8中则使用了x86的优化指令atomic fetch-and-add ，上面的代码直接等价于cpu的一条指令atomic fetch-and-add .性能更好
而compareAndSet利用JNI来完成CPU指令的操作。
public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 注意 java.util.concurrent.atomic中的原子类使用了很多cas，但是这个方法一个是自己实现和使用需要很仔细，另一个在真的高并发中可能陷入死循环，因为方法中本身就是一个死循环：for (;;).java8为此提供了LongAdder.
关于垃圾自动回收的语言不会出现cas中aba问题的原理：stackoverflow
</content>
    </entry>
    
     <entry>
        <title>Java concurrency 5 Synchronizer and AQS</title>
        <url>https://xiongdahu.github.io/post/java-concurrency-5-synchronizer-and-aqs/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  好难，看不懂呀！ 先自己写一个CountDownLatch的示例： CountDownLatch是管理一组线程和一个主线程的先后。主线程wait后就阻塞，直到所有的CountDownLatch调用countDown后主线程接着开始。
package angus.intrview.concurrent; import java.util.concurrent.CountDownLatch; import java.util.concurrent.TimeUnit; public class CountDownLatchTest { // 这个方法将启动多个任务，并让它们同时执行，计算完成的时间 	public long timer(int taskNums) throws InterruptedException { CountDownLatch startLatch = new CountDownLatch(1); CountDownLatch finishLatch = new CountDownLatch(taskNums); for (int i = 0; i &amp;lt; taskNums; i&#43;&#43;) { Task task = new Task(startLatch, finishLatch, i); new Thread(task).start(); } long start = System.nanoTime(); startLatch.countDown();// 准备好线程后开始同时启动所有任务 	finishLatch.await();// 等待任务完成 	long end = System.nanoTime(); return end - start; } public static void main(String[] args) throws InterruptedException { CountDownLatchTest ct = new CountDownLatchTest(); long time = ct.timer(100); System.out.println(TimeUnit.NANOSECONDS.toSeconds(time) &#43; &amp;#34; SENCODS&amp;#34;); } } class Task implements Runnable { CountDownLatch startLatch; CountDownLatch finishLatch; int time; Task(CountDownLatch startLatch, CountDownLatch finishLatch, int time) { this.startLatch = startLatch; this.finishLatch = finishLatch; this.time = time; } @Override public void run() { try { startLatch.await();// 等待主线程通知任务开始 	System.out.println(&amp;#34;doing the task!&amp;#34;); Thread.sleep(time * 100); // 模拟任务过程 	} catch (InterruptedException e1) { // TODO Auto-generated catch block 	e1.printStackTrace(); } finally { System.out.println(&amp;#34;task done&amp;#34;); finishLatch.countDown();// 告诉主线程任务完成 	} } } CyclicBarrier // pass</content>
    </entry>
    
     <entry>
        <title>Java-==-and-equal</title>
        <url>https://xiongdahu.github.io/post/java-and-equal/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html"> /** * samples for == and equal() * @author hsiung * */ class TestObj { // the class for test == and equal() } public class EqualAndCompare { public static void main(String[] args) { TestObj obj1 = new TestObj(); TestObj obj2 = new TestObj(); TestObj obj3 = obj1; System.out.println(obj1 == obj2);// false , 	// == Compares references, not values 	System.out.println(obj1 == obj3);// true  System.out.println(obj1.equals(obj2));// false, 	// equal() method is derived from java.lang.Object, if not override,nor 	// in superclass,then equal behave as same as == 	// Always remember to override hashCode if you override equals so as not 	// to &amp;#34;break the contract&amp;#34;. 	// As per the API, the result returned from the hashCode() method for 	// two objects must be the same if their equals methods shows that they 	// are equivalent. The converse is not necessarily true.  String s1 = &amp;#34;haha&amp;#34;;// constant pool 	String s2 = new String(&amp;#34;haha&amp;#34;);// defined in ?heap 	System.out.println(s1 == s2);// false ,== Compares references, not 	// values, there is a exception for 	// static field in class, static String 	// in class == and equal both always 	// return *true* 	// for more infomation，see : 	// http://stackoverflow.com/questions/7520432/what-is-the-difference-between-vs-equals-in-java  System.out.println(s1.equals(s2)); // true compare the 	// value  String s3 = s2.intern();// find the same value String in constant pool 	System.out.println(s1 == s3);// true  int i1 = 2;// primitive type has no equal() method 	Integer i3 = Integer.valueOf(2); System.out.println(i1 == i3);// true, i3 automatic unboxing into int; 	System.out.println(i3.equals(i1));// auto boxing into Integer  Integer i2 = 2; System.out.println(i3.compareTo(i2)); } /* * Comparable interface, a.compareTo(b) return -1：less,0:equal,1:greater. 0 * should always be returned for objects when the .equals() comparisons * return true. All Java classes that have a natural ordering implement this * (String, Double, BigInteger, ...). * * * Comparator interface: is a util for compare two instance,then you can use * the comparator to sort array and other things * */ }</content>
    </entry>
    
     <entry>
        <title>Java-AOP-sample</title>
        <url>https://xiongdahu.github.io/post/java-aop-sample/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html"> 找到一个最简单的介绍，不怎么想翻译，直接看原文吧:
A Simple Introduction to AOP
提醒个点，使用注解的方式写切面时，增加了一个空方法，即：
@Pointcut(&amp;#34;execution(* org.bk.inventory.service.*.*(..))&amp;#34;) public void serviceMethods(){ } 在使用xml配置的话，就不需要这个方法了，serviceMethods方法名是后面配置切点的引用。
如果不想引入spring的话，可以直接使用aspectj或者jboss aop。
</content>
    </entry>
    
     <entry>
        <title>Java-动态代理</title>
        <url>https://xiongdahu.github.io/post/java-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  好文 Java 动态代理机制分析及扩展
更深入的一篇:
java设计模式-动态代理模式
优势 相比 静态代理，动态代理具有更强的 灵活性，因为它不用在我们设计实现的时候就指定 某一个代理类来代理哪一个被代理对象，我们可以把这种指定延迟到程序运行时由 JVM来实现。
实例 动态代理类接口，接口规范方法。
package angus.interview.proxy; public interface Subject { public void request(); } 需要被代理的真实的类:
package angus.interview.proxy; public class SubjectImpl implements Subject { @Override public void request() { System.out.println(&amp;#34; subject request&amp;#34;); } } 先创建一个代理类。然后利用反射创建一个用真实类加载器创建的一个对象。该对象调用request方法实际上调用的是代理类的invoke方法。
package angus.interview.proxy; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy implements InvocationHandler { private Object target; public Object bind(Object target) { this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); // 要绑定接口this(这是一个缺陷，cglib弥补了这一缺陷) 	} @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&amp;#34;------------------before------------------&amp;#34;); Object result = method.invoke(target, args); System.out.println(&amp;#34;-------------------after------------------&amp;#34;); return result; } } static void main(){ DynamicProxy proxy = new DynamicProxy(); Subject subject= proxy.bind(SubjectImpl); subject.request(); } 和静态代理模式比较的好处
在静态代理模式时,一个真实角色必须对应一个代理角色,如果大量使用会导致类的急剧膨胀;而动态代理则不会有这个问题，我们将接口中的方法委托给invoke方法，并在invoke中实现拦截。
源码分析 参考:http://rejoy.iteye.com/blog/1627405 主要原来:生成了一个代理类的class文件。 Proxy.newProInstance()方法
public static Object newProxyInstance(ClassLoader loader,Class&amp;lt;?&amp;gt;[] interfaces,InvocationHandler h) throws IllegalArgumentException { if (h == null) { throw new NullPointerException(); } final Class&amp;lt;?&amp;gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkProxyAccess(Reflection.getCallerClass(), loader, intfs); } // 这里是生成class的地方  Class&amp;lt;?&amp;gt; cl = getProxyClass0(loader, intfs); // 使用我们实现的InvocationHandler作为参数调用构造方法来获得代理类的实例  try { final Constructor&amp;lt;?&amp;gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (sm != null &amp;amp;&amp;amp; ProxyAccessHelper.needsNewInstanceCheck(cl)) { return AccessController.doPrivileged(new PrivilegedAction&amp;lt;Object&amp;gt;() { public Object run() { return newInstance(cons, ih); } }); } else { return newInstance(cons, ih); } } catch (NoSuchMethodException e) { throw new InternalError(e.toString()); } }  其中newInstance只是调用Constructor.newInstance来构造相应的代理类实例，这里重点是看getProxyClass0这个方法的实现:
private static Class&amp;lt;?&amp;gt; getProxyClass0(ClassLoader loader, Class&amp;lt;?&amp;gt;... interfaces) { // 代理的接口数量不能超过65535，这是class文件格式决定的  if (interfaces.length &amp;gt; 65535) { throw new IllegalArgumentException(&amp;#34;interface limit exceeded&amp;#34;); } // JDK对代理进行了缓存，如果已经存在相应的代理类，则直接返回，否则才会通过ProxyClassFactory来创建代理  return proxyClassCache.get(loader, interfaces); } 其中代理缓存是使用WeakCache实现的，如下
private static final WeakCache&amp;lt;ClassLoader, Class&amp;lt;?&amp;gt;[], Class&amp;lt;?&amp;gt;&amp;gt; proxyClassCache = new WeakCache&amp;lt;&amp;gt;(new KeyFactory(), new ProxyClassFactory()); 具体的缓存逻辑这里暂不关心，只需要关心ProxyClassFactory是如何生成代理类的，ProxyClassFactory是Proxy的一个静态内部类，实现了WeakCache的内部接口BiFunction的apply方法:
private static final class ProxyClassFactory implements BiFunction&amp;lt;ClassLoader, Class&amp;lt;?&amp;gt;[], Class&amp;lt;?&amp;gt;&amp;gt; { // 所有代理类名字的前缀  private static final String proxyClassNamePrefix = &amp;#34;$Proxy&amp;#34;; // 用于生成代理类名字的计数器  private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&amp;lt;?&amp;gt; apply(ClassLoader loader, Class&amp;lt;?&amp;gt;[] interfaces) { // 省略验证代理接口的代码……  String proxyPkg = null; // 生成的代理类的包名  // 对于非公共接口，代理类的包名与接口的相同  for (Class&amp;lt;?&amp;gt; intf : interfaces) { int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) { String name = intf.getName(); int n = name.lastIndexOf(&amp;#39;.&amp;#39;); String pkg = ((n == -1) ? &amp;#34;&amp;#34; : name.substring(0, n &#43; 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( &amp;#34;non-public interfaces from different packages&amp;#34;); } } } // 对于公共接口的包名，默认为com.sun.proxy[源码](http://hg.openjdk.java.net/jdk6/jdk6/jdk/rev/695dd7ceb9e3)  if (proxyPkg == null) { proxyPkg = ReflectUtil.PROXY_PACKAGE &#43; &amp;#34;.&amp;#34;; } // 获取计数  long num = nextUniqueNumber.getAndIncrement(); // 默认情况下，代理类的完全限定名为:com.sun.proxy.$Proxy0，com.sun.proxy.$Proxy1……依次递增  String proxyName = proxyPkg &#43; proxyClassNamePrefix &#43; num; // 这里才是真正的生成代理类的字节码的地方  byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces); try { // 根据二进制字节码返回相应的Class实例  return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { throw new IllegalArgumentException(e.toString()); } } } ProxyGenerator是sun.misc包中的类，它没有开源，但是可以反编译来一探究竟:
public static byte[] generateProxyClass(final String var0, Class[] var1) { ProxyGenerator var2 = new ProxyGenerator(var0, var1); final byte[] var3 = var2.generateClassFile(); // 这里根据参数配置，决定是否把生成的字节码（.class文件）保存到本地磁盘，  //我们可以通过把相应的class文件保存到本地，再反编译来看看具体的实现，这样更直观  if(saveGeneratedFiles) { AccessController.doPrivileged(new PrivilegedAction() { public Void run() { try { FileOutputStream var1 = new FileOutputStream(ProxyGenerator.dotToSlash(var0) &#43; &amp;#34;.class&amp;#34;); var1.write(var3); var1.close(); return null; } catch (IOException var2) { throw new InternalError(&amp;#34;I/O exception saving generated file: &amp;#34; &#43; var2); } } }); } return var3; } saveGeneratedFiles这个属性的值从哪里来呢:
private static final boolean saveGeneratedFiles = ((Boolean)AccessController.doPrivileged( new GetBooleanAction(&amp;#34;sun.misc.ProxyGenerator.saveGeneratedFiles&amp;#34;))).booleanValue(); GetBooleanAction实际上是调用Boolean.getBoolean(propName)来获得的，而Boolean.getBoolean(propName)调用了System.getProperty(name)，所以我们可以设置sun.misc.ProxyGenerator.saveGeneratedFiles这个系统属性为true来把生成的class保存到本地文件来查看。
反编译class文件
自己创建文件写入生成的动态代理类:
package angus.interview.proxy; import java.io.FileOutputStream; import java.io.IOException; import sun.misc.ProxyGenerator; @SuppressWarnings(&amp;#34;restriction&amp;#34;) public class ProxyGeneratorUtils { public static void writeProxyClassToHardDisk(String path) { // 获取代理类的字节码 	byte[] classFile = ProxyGenerator.generateProxyClass(&amp;#34;$Proxy11&amp;#34;, SubjectImpl.class.getInterfaces()); FileOutputStream out = null; try { out = new FileOutputStream(path); out.write(classFile); out.flush(); } catch (Exception e) { e.printStackTrace(); } finally { try { out.close(); } catch (IOException e) { e.printStackTrace(); } } } } 测试我们的工具类:
package angus.interview.proxy; public class TestProxy { public static void main(String[] args) { System.getProperties().put(&amp;#34;sun.misc.ProxyGenerator.saveGeneratedFiles&amp;#34;, &amp;#34;true&amp;#34;); DynamicProxy proxy = new DynamicProxy(); Subject sproxy = (Subject) proxy.bind(new SubjectImpl()); sproxy.request(); ProxyGeneratorUtils.writeProxyClassToHardDisk(&amp;#34;$Proxy11.class&amp;#34;); } } 刷新目录，得到一个$Proxy11.class,反编译使用Java Decompiler，GUI傻瓜式，支持最新语法，编译慢，效果好:
可以看到
$Proxy11继承Proxy，并实现了Subject，同时我们写的那个InvocationHandler的子类DynamicProxy也被传递进去了。
重点看request方法的代码，只有一行 this.h.invoke(this, m3, null);其中h的引用就是DynamicProxy.
m3就是m3 = Class.forName(&amp;quot;angus.interview.proxy.Subject&amp;quot;).getMethod(&amp;quot;request&amp;quot;, new Class[0]);
import angus.interview.proxy.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy11 extends Proxy implements Subject { private static Method m1; private static Method m2; private static Method m3; private static Method m0; public $Proxy11(InvocationHandler paramInvocationHandler) { super(paramInvocationHandler); } public final boolean equals(Object paramObject) { try { return ((Boolean)this.h.invoke(this, m1, new Object[] { paramObject })).booleanValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final String toString() { try { return (String)this.h.invoke(this, m2, null); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final void request() { try { this.h.invoke(this, m3, null); return; } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final int hashCode() { try { return ((Integer)this.h.invoke(this, m0, null)).intValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } static { try { m1 = Class.forName(&amp;#34;java.lang.Object&amp;#34;).getMethod(&amp;#34;equals&amp;#34;, new Class[] { Class.forName(&amp;#34;java.lang.Object&amp;#34;) }); m2 = Class.forName(&amp;#34;java.lang.Object&amp;#34;).getMethod(&amp;#34;toString&amp;#34;, new Class[0]); m3 = Class.forName(&amp;#34;angus.interview.proxy.Subject&amp;#34;).getMethod(&amp;#34;request&amp;#34;, new Class[0]); m0 = Class.forName(&amp;#34;java.lang.Object&amp;#34;).getMethod(&amp;#34;hashCode&amp;#34;, new Class[0]); return; } catch (NoSuchMethodException localNoSuchMethodException) { throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); } catch (ClassNotFoundException localClassNotFoundException) { throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); } } }</content>
    </entry>
    
     <entry>
        <title>Java-注解和注解处理器sample</title>
        <url>https://xiongdahu.github.io/post/java-%E6%B3%A8%E8%A7%A3%E5%92%8C%E6%B3%A8%E8%A7%A3%E5%A4%84%E7%90%86%E5%99%A8sample/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  注解处理 注解是jdk1.5出现的,但是自定义处理注解的功能是1.6才有的.Element等关于注解源码抽象的支持类都是1.6出现的.
关于注解的定义就不说了,主要说说注解处理
本文根据以下资料并进行部分修改：
JavaAnnotationProcessing
基本知识 annotation processing integrated into javac compiler
– since Java 6.0; known as pluggable annotation processing
– compiler automatically searches for annotation processors
– unless disabled with -proc:noneoption for javac
– processors can be specified explicitly with -processor option for javac or -cp processor.jar,processor.jar include /META-INF/service/javax.annotation.processing.Processor file and your processor decalared in file;
implement a processor class
– must implement Processor interface
– typically derived from AbstractProcessor
– new package javax.annotation.processing
同时自定义注解处理器需要指定注解选项： specify supported annotation &#43; options
– by means of annotations:
@SupportedAnnotationTypes
@SupportedOptions
@SupportedSourceVersion
编译器编译源码是会有很多轮(round)：
1st round：编译器得到所有的注解-获取所有的注解处理器-进行match并process,如果匹配的处理器中process方法的返回值是true,表示该注解被 claim,不再查询其他处理器.如果是false,接着查询匹配处理器处理,所以注解处理器在META-INF/services/javax.annotation.processing.Processor声明顺序是有关系的&amp;ndash; 所有的注解都被claim后,注解处理完成.
如果注解处理器产生新的java文件,那么新的一轮处理开始,前面被调用的那些处理器又被调用,直到没有java文件产生.
最后一轮又要调用一遍所有处理器,完成他们的各自工作.
最最后,编译器编译源码和注解处理器生成的源码.
还有一个很重要的类AbstractProcessor： 有一个引用processingEnv
提供了两个重要工具类：
– Filer for creation of new source, class, or auxiliary files
– Messager to report errors, warnings, and other notices
此外，一个产生java文件的重要方法：
FileObject sourceFile = processingEnv.getFiler().createSourceFile(beanClassName); process() method takes 2 arguments: Set&amp;lt;? extends TypeElement&amp;gt; annotations – the annotation types requested to be processed – subset of the supported annotations RoundEnvironment roundenv – environment for information about the current and prior round – supplies elements annotated with a given annotation or all root elements in the source  一个自定义的注解处理器格式如下：
@SupportedAnnotationTypes({&amp;#34;Property&amp;#34;}) @SupportedSourceVersion(SourceVersion.RELEASE_6) public class PropertyAnnotationProcessor extends AbstractProcessor { public boolean process(Set&amp;lt;? extends TypeElement&amp;gt; annotations, RoundEnvironment env) { process the source file elements using the mirror API } } jdk1.6 对注解的处理支持建立在对源码的抽象,Element是javax.lang.model.*中定义的,各种Element是对源码抽象数据结构,如：
package com.example;	// PackageElement public class Foo {	// TypeElement  private int a; // VariableElement  private Foo other; // VariableElement  public Foo () {} // ExecuteableElement  } TypeElement不能提供父类的信息,如果需要这些信息,需要从Element中得到TypeMirror.TypeMirror::element.asType()
实例： 动手写注解处理器：3个类,一个定义注解Comparator.java,一个使用注解的类Name.java,一个处理注解MyProcessor.java.
我将定义一个注解@Comparator,使用在方法上,被注释的方法能够返回一个Comparator.
一个注解处理器,解析所有被注释的方法,为每一个方法产生一个Comparator类.
！！！注意,这里的内容和连接中资料的已经不一样了,资料里给的process方法并不能产生比较器类.
给出注解定义前看看注解怎么使用：
// ./Name.java // ./ 表示当前命令行文件夹,后面所有的javc命令都以这个文件夹为准 package java.interview.annotation; public class Name { private final String first; private final String last; public Name(String f, String l) { first = f; last = l; } @Comparator(&amp;#34;NameByFirstNameComparator&amp;#34;) public int compareToByFirstName(Name other) { if (this == other) return 0; int result; if ((result = this.first.compareTo(other.first)) != 0) return result; return this.last.compareTo(other.last); } } 其中被注解注释的方法将产生一个NameByFirstNameComparator.java文件：
// ./angus/initerview/annotation/NameByFirstNameComparator.java  public class NameByFirstNameComparator implements java.util.Comparator&amp;lt;Name&amp;gt; { public int compare(Name o1, Name o2) { return o1.compareToByFirstName(o2); } public boolean equals(Object other) { return this.getClass() == other.getClass(); } } 我们定义注解：
// ./Comparator.java package angus.interview.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Comparator { String value(); } 接下来定义我们的注解处理器,有详细注解,特别注意generate源码中的空格和分号不要弄丢了：
package angus.interview.annotation; import java.io.IOException; import java.io.PrintWriter; import java.util.Set; import javax.annotation.processing.AbstractProcessor; import javax.annotation.processing.RoundEnvironment; import javax.annotation.processing.SupportedAnnotationTypes; import javax.annotation.processing.SupportedSourceVersion; import javax.lang.model.SourceVersion; import javax.lang.model.element.Element; import javax.lang.model.element.ExecutableElement; import javax.lang.model.element.TypeElement; import javax.lang.model.type.PrimitiveType; import javax.lang.model.type.TypeKind; import javax.lang.model.type.TypeMirror; import javax.tools.Diagnostic; import javax.tools.FileObject; @SupportedAnnotationTypes({ &amp;#34;angus.interview.annotation.Comparator&amp;#34; }) @SupportedSourceVersion(SourceVersion.RELEASE_8) public class MyProcessor extends AbstractProcessor { @Override public boolean process(Set&amp;lt;? extends TypeElement&amp;gt; annotations, RoundEnvironment roundEnv) { for( final Element element: roundEnv.getElementsAnnotatedWith( Comparator.class ) ) { if(element instanceof ExecutableElement){ ExecutableElement m = (ExecutableElement) element; TypeElement className = (TypeElement)m.getEnclosingElement(); Comparator a = m.getAnnotation(Comparator.class); if (a != null) { TypeMirror returnType = m.getReturnType(); if (!(returnType instanceof PrimitiveType) || ((PrimitiveType) returnType).getKind() != TypeKind.INT) { processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR, &amp;#34;@Comparator can only be applied to methods that return int&amp;#34;); continue; } // prepare for java file generation 	// t m a mean ? 	String comparatorClassName = a.value(); String comparetoMethodName = m.getSimpleName().toString(); String theProcessedClassesName = className.getQualifiedName().toString(); try { writeComparatorFile(theProcessedClassesName, comparatorClassName, comparetoMethodName); } catch (IOException e) { e.printStackTrace(); } } } } return true;// claimed now,no need next processor 	} /* * * public class NameByFirstNameComparator implements java.util.Comparator&amp;lt;Name&amp;gt; { * public int compare(Name o1, Nameo2) { return o1.compareToByFirstName(o2); } * * public boolean equals(Object other) { return this.getClass() == other.getClass(); } } */ //!!!careful with spaces and &amp;#34;;&amp;#34;!!! 	private void writeComparatorFile(String fullClassName, String comparatorClassName, String compareToMethodName) throws IOException { int i = fullClassName.lastIndexOf(&amp;#34;.&amp;#34;); String packageName = fullClassName.substring(0, i); FileObject sourceFile = processingEnv.getFiler().createSourceFile(packageName &#43; &amp;#34;.&amp;#34; &#43; comparatorClassName); if (sourceFile == null) { System.out.println(&amp;#34;create source file failed&amp;#34;); } PrintWriter out = new PrintWriter(sourceFile.openWriter()); if (i &amp;gt; 0) { out.println(&amp;#34;package &amp;#34; &#43; packageName &#43; &amp;#34;;&amp;#34;); } String parametrizedType = fullClassName.substring(i &#43; 1);//!! 	out.println( &amp;#34;public class &amp;#34; &#43; comparatorClassName &#43; &amp;#34; implements java.util.Comparator&amp;lt;&amp;#34; &#43; parametrizedType &#43; &amp;#34;&amp;gt; {&amp;#34;); out.println(); out.println(&amp;#34;public int compare( &amp;#34; &#43; parametrizedType &#43; &amp;#34; o1 , &amp;#34; &#43; parametrizedType &#43; &amp;#34; o2 ){&amp;#34;); out.println(&amp;#34;return o1.&amp;#34; &#43; compareToMethodName &#43; &amp;#34;(o2);&amp;#34;); out.println(&amp;#34;}&amp;#34;); out.println(); out.println(); out.println(&amp;#34;public boolean equals(Object other) {&amp;#34;); out.println(&amp;#34;return this.getClass() == other.getClass();&amp;#34;); out.println(&amp;#34;}&amp;#34;); out.println(&amp;#34;}&amp;#34;); out.close(); } } 测试处理器 两种方法,
一种是使用 -cp：
在项目的根目录中（pom.xml同级目录）新建META-INF文件夹,并在里面新建services文件夹,再在里面新建一个文件 javax.annotation.processing.Processor,并在该文件中注册我们的处理器,第一行写入：angus.interview.annotation.MyProcessor.
然后用eclipse将项目export得到一个jar包,jar必须包含target文件夹（处理器class文件）和META-INF文件夹（注册处理器）.这里将jar包命名为process.jar. 复制jar包到Name.java目录中,并在该目录打开终端,输入：
 javac -cp process.jar Name.java
 将会得到Name.class文件和一个angus文件夹,最里面是NameByFirstNameComparator.java和NameByFirstNameComparator.class.
打开NameByFirstNameComparator.java,发现内容和上面给出的一模一样.
第二种方法是使用-processor参数,但是还没搞懂MyProcessor.class应该放在哪里.暂时先到这.
</content>
    </entry>
    
     <entry>
        <title>gradle笔记1-理解build脚本基本语法</title>
        <url>https://xiongdahu.github.io/post/gradle-%E7%90%86%E8%A7%A3build%E8%84%9A%E6%9C%AC%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html"> 在看这个之前，希望你有用ant或者maven的使用经验，还有，对groovy的语法有一个简单的了解，不懂也没关系，下面会介绍。
理解gradle文件的前提是理解一个重要的groovy概念:closure
closure 一个closure是一个定义在groovy文件中的{}代码块，这个代码块类似js中的匿名函数，它可以被赋值给变量，可以被调用，可以接收参数，还可以作为参数传递给别的函数。
closure中最重要的两个概念是委托对象和作为参数传递的语法格式（理解gradle文件很重要）。
groovy方法调用括号的省略 groovy提供非常优雅的方法调用格式，总结起来是:
//可以省略参数括号，并且链式调用 // equivalent to: turn(left).then(right) turn left then right //groovy数字可以直接转换成字符串 // equivalent to: take(2.pills).of(chloroquinine).after(6.hours) take 2.pills of chloroquinine after 6.hours //两个参数用逗号隔开 // equivalent to: paint(wall).with(red, green).and(yellow) paint wall with red, green and yellow //命名参数用冒号 // with named parameters too // equivalent to: check(that: margarita).tastes(good) check that: margarita tastes good //闭包作为参数也可以省略括号 // with closures as parameters // equivalent to: given({}).when({}).then({}) given { } when { } then { } //没有参数的方法必须有括号 // equivalent to: select(all).unique().from(names) select all unique() from names //如果调用链元素为奇数，那么最后一个元素是前面方法链返回对象的属性 //cookies 是take(3)返回值的一个属性 // equivalent to: take(3).cookies // and also this: take(3).getCookies() take 3 cookies 上面调用的格式是dsl的基础。也是看懂gradle文件格式的基础。
让我们再深入一点，上面讲的是调用格式，那么怎么创建这种可以链式调用的方法呢？
 groovy和scala的方法返回值不需要return，最后一行就是返回值。
 closure是一个匿名函数，格式{ [closureParameters -&amp;gt; ] statements }，默认自带一个名为it的参数，所以只接受一个参数时可以省略-&amp;gt;。
 closure可以访问scope（作用域）内任何变量。并且这个scope是可以通过委托来改变的。
 groovy中Map对象的value如果是closure，那么可以接着调用:mapp.keyy({closure})
有了上面的基础，我们看一个简单的例子:
  //将closure赋值给一个变量，这个closure接收一个参数，参数名是默认的，it show = { println it } square_root = { Math.sqrt(it) } //为了容易理解，我将参数的type都添加上了， //please方法需要一个closure，接着返回一个map，map的key是the，value是一个closure， //这个closure接收一个closure，并返回一个map，这个map的of的value又是一个closure(不要晕了) //最后一个closure接收一个参数n。 def please(Closure action) { [the: { Closure what -&amp;gt; [of: { n -&amp;gt; action(what(n)) }] }] } //调用: // 等价: please(show).the(square_root).of(100) please show the square_root of 100 // ==&amp;gt; 10.0 总结一下就是，将你需要的操作封装成一个closure，给一个直观的命名，保证整个DSL调用语句有语义，定义返回一个map的函数作为入口，map的key是方法名，value是closure，这样可以在key后面传递一个closure接着调用这个value。
委托对象 gradle脚本是一个配置脚本，类似maven中pom.xml文件，不过gradle脚本更为强大，因为.gradle文件就是grrovy文件，所以还可以在脚本里面直接定义groovy对象让脚本使用。
委托对象就是一个groovy对象，用来执行gradle构建脚本中的closure。
as a build script executes, it configures an object of type Project. This object is called the delegate object of the script. The following table shows the delegate for each type of Gradle script. 三种不同的gradle脚本对应的委托对象 Build script（build.gradle） -&amp;gt;Project Init script	-&amp;gt;Gradle Settings script(setting.gradle)	-&amp;gt;Settings 构建中的每一个project，Gradle都会创建一个Project对象，并将这个对象与构建脚本相关联。
Project对象与build.gradle是一对一的关系。
Gradle的脚本是配置脚本，当脚本执行时，它是在配置某一个特殊类型的对象。比如一个构建脚本的执行，它就是在配置一个Project类型的对象。这个对象叫做脚本的代理对象。
委托有个重要的概念就是scope，指closure的变量引用范围:有时变量不在当前scope中，但是可以通过委托，改变closure的委托对象，这样就拥有了委托者的scope，从而可以在closure中使用委托者的变量。
关于groovy closure 的委托有三个重要属性
• this: refers to the instance of the class that the closure was defined in. • owner: is the same as this, unless the closure was defined inside another closure in which case the owner refers to the outer closure. • delegate: is the same as owner. But, it is the only one that can be programmatically changed, and it is the one that makes Groovy closures really powerful. the closure itself will be checked first, followed by the closure&amp;#39;s this scope, than the closure&amp;#39;s owner, then its delegate. However, Groovy is so flexible this strategy can be changed. Every closure has a property called resolvedStrategy. This can be set to: • Closure.OWNER_FIRST • Closure.DELEGATE_FIRST • Closure.OWNER_ONLY • Closure.DELEGATE_ONLY 来自 &amp;lt;https://dzone.com/articles/groovy-closures-owner-delegate&amp;gt;  gradle是dsl解析工具，是对groovy语法的扩展，build.gradle可以理解为就是一个.groovy文件，gradle会解析这个文件，发现里面的closure，并将这些closure委托给一个对象去执行。
gradle将groovy的委托机制发挥到极致，要理解gradle内部，就要理解closure的委托！！
closure作为参数传递 将closure作为参数传递的方法有多种:
//method accepts 1 parameter - closure myMethod(myClosure) //if method accepts only 1 parameter - parentheses can be omitted myMethod myClosure //I can create in-line closure myMethod {println &amp;#39;Hello World&amp;#39;} //method accepts 2 parameters myMethod(arg1, myClosure) //or the same as &amp;#39;4&amp;#39;, but closure is in-line myMethod(arg1, { println &amp;#39;Hello World&amp;#39; }) //if last parameter is closure - it can be moved out of parentheses myMethod(arg1) { println &amp;#39;Hello World&amp;#39; } 注意第三种和最后一种调用方式，是不是和gradle文件中很眼熟？只不过在gradle脚本中出现的closure更加复杂，因为有closure嵌套！！！但是万变不离其宗。下面我们会介绍嵌套不过是委托链的表现。
看一个脚本代码:
buildscript { repositories { jcenter() } dependencies { classpath &amp;#39;com.android.tools.build:gradle:1.2.3&amp;#39; } } buildscript是一个方法，接收一个closure。至于这个方法在哪，可以定义在任何地方，但是可以肯定的是，这个方法一定能够被Project对象调用。
因为build.gradle脚本就是委托给Project对象执行的。事实上，Project对象也不是亲自执行这个方法，而是委托给ScriptHandler执行。
这里，我们ScriptHandler对象会搜索到两个配置closure:repositories和dependencies。我们可以在ScriptHandler api中搜索到这两个方法。从api中我们又发现:
传递给dependencies的closure又被委托给了DependencyHandler对象&amp;hellip;&amp;hellip;. 这就是委托链。
ScriptHandler api
Project api
注意:这里buildscript {&amp;hellip;}整体称为一个 script block。 脚本块就是一个接受closure参数的方法调用。还有的方法是不接受closure的，那些称为statement（看下面解释）。
 A script block is a method call which takes a closure as a parameter
 插件 先看看构建脚本的构成:
 A build script is made up of zero or more statements and script blocks. Statements can include method calls, property assignments, and local variable definitions. A script block is a method call which takes a closure as a parameter. The closure is treated as a configuration closure which configures some delegate object as it executes.
 就是说脚本有两种内容:script block和statement.
Project接口预先定义了几个block:
allprojects { }	Configures this project and each of its sub-projects. artifacts { }	Configures the published artifacts for this project. buildscript { }	Configures the build script classpath for this project. configurations { }	Configures the dependency configurations for this project. dependencies { }	Configures the dependencies for this project. repositories { }	Configures the repositories for this project. sourceSets { }	Configures the source sets of this project. subprojects { }	Configures the sub-projects of this project. publishing { }	Configures the PublishingExtension added by the publishing plugin. 这些closure参数基本都是委托给其他对象执行的。
可以看到，Project对象的方法是有限而且通用的。真正有用的是插件，gradle的很多功能也是通过官方写的插件提供的。
如果你看到一个顶级层的something { ... }block，但是在Project源码中没有找到something block的任何信息。那么这个方法就是通过插件提供的。gradle自带很多插件,像java，eclipse,groovy，android等。
看一个实际的例子:
在andoird开发中的构建脚本:
apply plugin: &amp;#39;com.android.application&amp;#39; android { compileSdkVersion 22 buildToolsVersion &amp;#34;22.0.1&amp;#34; defaultConfig { applicationId &amp;#34;com.trickyandroid.testapp&amp;#34; minSdkVersion 16 targetSdkVersion 22 versionCode 1 versionName &amp;#34;1.0&amp;#34; } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile(&amp;#39;proguard-android.txt&amp;#39;), &amp;#39;proguard-rules.pro&amp;#39; } } } 这里，出现了android{},Project对象并没有这个script block。所以，这其实是由插件提供的block。我们找到com.android.application入口代码
extension = project.extensions.create(&amp;#39;android&amp;#39;, AppExtension, this, (ProjectInternal) project, instantiator, buildTypeContainer, productFlavorContainer, signingConfigContainer) setDefaultConfig(extension.defaultConfig, extension.sourceSetsContainer) extensions是一个ExtensionContainer实例，其中create API:
&amp;lt;T&amp;gt; T create(String name, Class&amp;lt;T&amp;gt; type, Object... constructionArguments)
这里就创建了一个android属性，是一个AppExtension对象，我们在脚本中提供给android block的{}其实是配置了一个AppExtension对象。我们可以在AppExtension中找到compileSdkVersion等属性。
所以，插件扩展的Project对象，提供了很多方法，这样，可以在脚本中使用插件定义的方法（script block）了。
一个插件就是实现实现了org.gradle.api.Plugin接口的groovy类。
我们看怎么写一个插件:
//build.gradle apply plugin: GreetingPlugin //这里提供closure 来配置插件提供的greeting script block greeting { message = &amp;#39;Hi&amp;#39; greeter = &amp;#39;Gradle&amp;#39; } class GreetingPlugin implements Plugin&amp;lt;Project&amp;gt; { void apply(Project project) {//注意我们是如果扩展Project对象的，通过extensions对象创建一个script block:greeting,而这个block关联的是一个对象  project.extensions.create(&amp;#34;greeting&amp;#34;, GreetingPluginExtension) project.task(&amp;#39;hello&amp;#39;) &amp;lt;&amp;lt; { //注意我们是如何使用greeting的，没有通过extensioins  println &amp;#34;${project.greeting.message} from ${project.greeting.greeter}&amp;#34; } } } class GreetingPluginExtension { String message String greeter } /* project.task(&amp;#39;hello&amp;#39;) &amp;lt;&amp;lt; { println &amp;#34;${project.greeting.message} from ${project.greeting.greeter}&amp;#34; } 使用了重载操作符，等价: project.task(&amp;#39;hello&amp;#39;).leftShift({ println &amp;#34;${project.greeting.message} from ${project.greeting.greeter}&amp;#34; }) */ 官方文档:如何自己写一个插件
参考: gradle-tip-2
Gradle深入与实战（六）Gradle的背后是什么？
DSL语法 gradle使用的基于groovy中的DSL语法，所谓的dsl，就是基于groovy发明的新的“编程语言”，gradle dsl是groovy的超集，就是你可以完全使用groovy的语法，但是你还是会看到很多不是groovy语法，这时不要困惑，这些语法不过是gradle利用groovy提供的元编程能力提供的新语法。
以新建task的语法为例，在Project API中有四个重载形式:
Task task(String name, Closure configureClosure); Task task(Map&amp;lt;String, ?&amp;gt; args, String name, Closure configureClosure); Task task(Map&amp;lt;String, ?&amp;gt; args, String name) throws InvalidUserDataException; Task task(String name) throws InvalidUserDataException; 但是你会看到这样的调用方式:
task intro(dependsOn: hello) { doLast { println &amp;#34;I&amp;#39;m Gradle&amp;#34; } } 这是dsl，具体的解析方式在TaskDefinitionScriptTransformer
具体见我在sf的提问gradle task method syntax in build.gradle
more tips gradle-tips
</content>
    </entry>
    
     <entry>
        <title>单例模式和序列化</title>
        <url>https://xiongdahu.github.io/post/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E5%BA%8F%E5%88%97%E5%8C%96/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html">  参考资料
饱汉式 public class Singleton { private static Singleton instance = null private Singleton (){} public static Singleton getInstance() { if(instance == null) instance = new Singleton(); return instance; } } //饱汉式，使用时创建 饿汉式 //加载时创建对象 static public class Singleton { private Singleton instance = null; static { instance = new Singleton(); } private Singleton (){} public static Singleton getInstance() { return this.instance; } } ```	### 静态内部类 public class Singleton {
private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; }  }
//这个比较好，线程安全，也达到了延迟加载效果。
### 枚举类 //这个是最好的 这种方式是Effective Java作者Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊
public enum Singleton { INSTANCE; public void whateverMethod() { }  }
访问这个单例 Singleton.INSTANCE
### 双重校验锁 其实是不安全的，多线程开销很大，甚至死锁。原因在于指令重排序。public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; }  }
### 序列化 使用静态内部类举例，只要提供一个readResolve方法 ```	public class Singleton { private Singleton (){} private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } private Object readResolve() throws ObjectStreamException{ return SingletonHolder.INSTANCE; } } 无论是实现Serializable接口，或是Externalizable接口，当从I/O流中读取对象时，readResolve()方法都会被调用到。实际上就是用readResolve()中返回的对象直接替换在反序列化过程中创建的对象，而被创建的对象则会被垃圾回收掉。
</content>
    </entry>
    
     <entry>
        <title>面试题-类加载过程和子类重写父类方法的调用</title>
        <url>https://xiongdahu.github.io/post/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%E5%92%8C%E5%AD%90%E7%B1%BB%E9%87%8D%E5%86%99%E7%88%B6%E7%B1%BB%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/</url>
        <categories>
          <category>编程</category>
        </categories>
        <tags>
          <tag>java</tag><tag>code</tag>
        </tags>
        <content type="html"> 最近一道非常火的携程面试题:
public class Base { private String baseName = &amp;#34;base&amp;#34;; public Base() { callName(); } public void callName() { System.out.println(baseName); } static class Sub extends Base { private String baseName = &amp;#34;sub&amp;#34;; public void callName() { System.out.println(baseName) ; } } public static void main(String[] args) { Base b = new Sub();//输出？  } } 我的理解：
先理解两个方法:
class 的(clinit)方法和(init)方法不同：这两个方法一个是虚拟机在装载一个类初始化的时候调用的（&amp;lt;clinit&amp;gt;）。另一个是在类实例化时调用的（&amp;lt;init&amp;gt;）。
在加载类时需要类的初始化，JVM对应的字节码方法是&amp;lt;clinit&amp;gt;，这个方法会初始化static变量和执行static{}代码块，按源码定义的顺序执行。注意：如果static{}代码块中引用了static 变量，那么一定要使用之前定义static变量。ide会提示的。
这时，class的其他成员变量和方法都没有被执行。变量的内存都已经分配，值为null或者0（基本类型），false(布尔类型)。
当创建一个类的实例时，此时会调用&amp;lt;init&amp;gt;方法,这个方法会初始化非static变量和执行{}代码块。注意，这两个也是按源码顺序执行的。所以代码块如果要使用非static变量，一定要先定义。同样ide一般会提示的。但是要明白这个顺序。
以上说的执行顺序通过eclipse调试可以确定是正确的。
所以组合起来 创建一个类的实例对象需要下面的顺序：
父类P static代码块和static变量初始化 -&amp;gt; 子类S static代码块和static变量初始化 -&amp;gt; 父类P 非static代码块和非static变量初始化 -&amp;gt; 父类P构造函数 -&amp;gt; 子类S非static代码块和非static变量初始化 -&amp;gt; 子类S构造函数 回到面试题：我们看看创建一个实例对象的调用栈：
可以看到依次进入16， 8， 21行代码:
16行：static class Sub extends Base
8行：callName();//Base()构造函数中
21行：System.out.println (baseName) ;//Sub的callName()
根据前面的分析，这个类没有static代码块和static变量，也没有代码块。所以第一个执行的是父类非静态成员的base=&amp;laquo;base&amp;raquo;;接着执行构造函数Base();这里到了魔法的一步，调用的callName()是子类（21行）的方法。这个行为就是动态单分派。详细资料看最后。由于子类的非static变量初始化没有完成，所有子类中的base变量是null。输出也是null。
！！！所以，不要再构造函数中调用可能会被子类覆盖的方法。
有的面试题会出现陷阱:在调用callName()方法改为this.callName(). 其实都是一样的。在调用Base构造函数时没有Base的实例对象，调用者其实还是Base$Sub这个类。
还有一个进阶版：
public class Basic { public void add(int i) { System.out.println(&amp;#34;Basic add&amp;#34;); } public Basic() { add(&amp;#39;a&amp;#39;); } public static void main(String[] args) { Basic a = new A(); B b = new B(); } } class A extends Basic { public void add(int i) { System.out.println(&amp;#34;A add&amp;#34;); } } class B extends Basic { public void add(char i) { System.out.println(&amp;#34;B add&amp;#34;); } } 不仅考察单分派，还有重载的静态多分派。
进阶版问题的解释需以下知识点：
java的静态分派和动态单分派资料：
CSDN-类加载机制-深入java虚拟机 读书笔记
方法分派
重载是静态多分派，编译时期确定。
覆盖是动态单分派，运行时通过实际类型绑定。
静态多分派:
静态分派 意思是 所有依赖静态类型来定位方法执行版本的分派过程就叫做静态分派，静态分派最典型的应用就是方法重载。
动态单分派:
动态单分派 意思是 根据运行期实际类型确定方法执行版本的分派过程叫做动态分派，动态分派最典型的应用就是方法重写。
同时理解，动态单分派就是多态，java的面向接口编程的根基就是多态。
</content>
    </entry>
    
</search>